{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d57ea29a",
   "metadata": {},
   "source": [
    "# TON IOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d4b25",
   "metadata": {},
   "source": [
    "## Primer fichero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f56df6",
   "metadata": {},
   "source": [
    "### Carga y Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53901c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from DataProcessor import DataProcessor\n",
    "import pandas as pd\n",
    "\n",
    "Loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44657f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 17:41:40,682 - INFO - CSV file loaded successfully:           src_ip  src_port         dst_ip  dst_port proto service  \\\n",
      "0    3.122.49.24      1883  192.168.1.152     52976   tcp       -   \n",
      "1   192.168.1.79     47260  192.168.1.255     15600   udp       -   \n",
      "2  192.168.1.152      1880  192.168.1.152     51782   tcp       -   \n",
      "3  192.168.1.152     34296  192.168.1.152     10502   tcp       -   \n",
      "4  192.168.1.152     46608  192.168.1.190        53   udp     dns   \n",
      "\n",
      "       duration src_bytes  dst_bytes conn_state  ...  http_response_body_len  \\\n",
      "0  80549.530260   1762852   41933215        OTH  ...                       0   \n",
      "1      0.000000         0          0         S0  ...                       0   \n",
      "2      0.000000         0          0        OTH  ...                       0   \n",
      "3      0.000000         0          0        OTH  ...                       0   \n",
      "4      0.000549         0        298        SHR  ...                       0   \n",
      "\n",
      "   http_status_code  http_user_agent  http_orig_mime_types  \\\n",
      "0                 0                -                     -   \n",
      "1                 0                -                     -   \n",
      "2                 0                -                     -   \n",
      "3                 0                -                     -   \n",
      "4                 0                -                     -   \n",
      "\n",
      "   http_resp_mime_types        weird_name  weird_addl  weird_notice  label  \\\n",
      "0                     -  bad_TCP_checksum           -             F      0   \n",
      "1                     -                 -           -             -      0   \n",
      "2                     -  bad_TCP_checksum           -             F      0   \n",
      "3                     -                 -           -             -      0   \n",
      "4                     -  bad_UDP_checksum           -             F      0   \n",
      "\n",
      "     type  \n",
      "0  normal  \n",
      "1  normal  \n",
      "2  normal  \n",
      "3  normal  \n",
      "4  normal  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "2025-09-04 17:41:44,443 - INFO - CSV file loaded successfully:          src_ip  src_port         dst_ip  dst_port proto service  duration  \\\n",
      "0  192.168.1.30      1183  192.168.1.152      1183   tcp       -  0.000011   \n",
      "1  192.168.1.30      1183  192.168.1.184      1183   tcp       -  0.000017   \n",
      "2  192.168.1.30      1183  192.168.1.184      1183   tcp       -  0.000145   \n",
      "3  192.168.1.30      1183  192.168.1.152      1183   tcp       -  0.000010   \n",
      "4  192.168.1.30      1183  192.168.1.152      1183   tcp       -  0.000115   \n",
      "\n",
      "   src_bytes  dst_bytes conn_state  ...  http_response_body_len  \\\n",
      "0          0          0        REJ  ...                       0   \n",
      "1          0          0        REJ  ...                       0   \n",
      "2          0          0        REJ  ...                       0   \n",
      "3          0          0        REJ  ...                       0   \n",
      "4          0          0        REJ  ...                       0   \n",
      "\n",
      "   http_status_code  http_user_agent  http_orig_mime_types  \\\n",
      "0                 0                -                     -   \n",
      "1                 0                -                     -   \n",
      "2                 0                -                     -   \n",
      "3                 0                -                     -   \n",
      "4                 0                -                     -   \n",
      "\n",
      "   http_resp_mime_types weird_name  weird_addl  weird_notice  label type  \n",
      "0                     -          -           -             -      1  dos  \n",
      "1                     -          -           -             -      1  dos  \n",
      "2                     -          -           -             -      1  dos  \n",
      "3                     -          -           -             -      1  dos  \n",
      "4                     -          -           -             -      1  dos  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = Loader.load_dataset(\"../data/Network_dataset_1.csv\", file_type=\"csv\")\n",
    "df2 = Loader.load_dataset(\"../data/Network_dataset_9.csv\", file_type=\"csv\")\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a3673ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>...</th>\n",
       "      <th>http_response_body_len</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>http_user_agent</th>\n",
       "      <th>http_orig_mime_types</th>\n",
       "      <th>http_resp_mime_types</th>\n",
       "      <th>weird_name</th>\n",
       "      <th>weird_addl</th>\n",
       "      <th>weird_notice</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.122.49.24</td>\n",
       "      <td>1883</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>52976</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>80549.530260</td>\n",
       "      <td>1762852</td>\n",
       "      <td>41933215</td>\n",
       "      <td>OTH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_TCP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>47260</td>\n",
       "      <td>192.168.1.255</td>\n",
       "      <td>15600</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>1880</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>51782</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_TCP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>34296</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>10502</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OTH</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>46608</td>\n",
       "      <td>192.168.1.190</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>SHR</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_UDP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          src_ip  src_port         dst_ip  dst_port proto service  \\\n",
       "0    3.122.49.24      1883  192.168.1.152     52976   tcp       -   \n",
       "1   192.168.1.79     47260  192.168.1.255     15600   udp       -   \n",
       "2  192.168.1.152      1880  192.168.1.152     51782   tcp       -   \n",
       "3  192.168.1.152     34296  192.168.1.152     10502   tcp       -   \n",
       "4  192.168.1.152     46608  192.168.1.190        53   udp     dns   \n",
       "\n",
       "       duration src_bytes  dst_bytes conn_state  ...  http_response_body_len  \\\n",
       "0  80549.530260   1762852   41933215        OTH  ...                       0   \n",
       "1      0.000000         0          0         S0  ...                       0   \n",
       "2      0.000000         0          0        OTH  ...                       0   \n",
       "3      0.000000         0          0        OTH  ...                       0   \n",
       "4      0.000549         0        298        SHR  ...                       0   \n",
       "\n",
       "   http_status_code  http_user_agent  http_orig_mime_types  \\\n",
       "0                 0                -                     -   \n",
       "1                 0                -                     -   \n",
       "2                 0                -                     -   \n",
       "3                 0                -                     -   \n",
       "4                 0                -                     -   \n",
       "\n",
       "   http_resp_mime_types        weird_name  weird_addl  weird_notice  label  \\\n",
       "0                     -  bad_TCP_checksum           -             F      0   \n",
       "1                     -                 -           -             -      0   \n",
       "2                     -  bad_TCP_checksum           -             F      0   \n",
       "3                     -                 -           -             -      0   \n",
       "4                     -  bad_UDP_checksum           -             F      0   \n",
       "\n",
       "     type  \n",
       "0  normal  \n",
       "1  normal  \n",
       "2  normal  \n",
       "3  normal  \n",
       "4  normal  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30eaba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 45 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   src_ip                  object \n",
      " 1   src_port                int64  \n",
      " 2   dst_ip                  object \n",
      " 3   dst_port                int64  \n",
      " 4   proto                   object \n",
      " 5   service                 object \n",
      " 6   duration                float64\n",
      " 7   src_bytes               object \n",
      " 8   dst_bytes               int64  \n",
      " 9   conn_state              object \n",
      " 10  missed_bytes            int64  \n",
      " 11  src_pkts                int64  \n",
      " 12  src_ip_bytes            int64  \n",
      " 13  dst_pkts                int64  \n",
      " 14  dst_ip_bytes            int64  \n",
      " 15  dns_query               object \n",
      " 16  dns_qclass              int64  \n",
      " 17  dns_qtype               int64  \n",
      " 18  dns_rcode               int64  \n",
      " 19  dns_AA                  object \n",
      " 20  dns_RD                  object \n",
      " 21  dns_RA                  object \n",
      " 22  dns_rejected            object \n",
      " 23  ssl_version             object \n",
      " 24  ssl_cipher              object \n",
      " 25  ssl_resumed             object \n",
      " 26  ssl_established         object \n",
      " 27  ssl_subject             object \n",
      " 28  ssl_issuer              object \n",
      " 29  http_trans_depth        object \n",
      " 30  http_method             object \n",
      " 31  http_uri                object \n",
      " 32  http_referrer           object \n",
      " 33  http_version            object \n",
      " 34  http_request_body_len   int64  \n",
      " 35  http_response_body_len  int64  \n",
      " 36  http_status_code        int64  \n",
      " 37  http_user_agent         object \n",
      " 38  http_orig_mime_types    object \n",
      " 39  http_resp_mime_types    object \n",
      " 40  weird_name              object \n",
      " 41  weird_addl              object \n",
      " 42  weird_notice            object \n",
      " 43  label                   int64  \n",
      " 44  type                    object \n",
      "dtypes: float64(1), int64(15), object(29)\n",
      "memory usage: 686.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Observe the DataFrame structure and types to check for any inconsistencies\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c3135aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid cleaning duplicates because it removes a lot of data and there are no identifiers that avoid the existance of duplicates by chance\n",
    "# df = Loader.clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6c38005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    0.883291\n",
       "0    0.116709\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot frequencies\n",
    "df[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b5dda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "dos         975261\n",
       "scanning    791321\n",
       "normal      233418\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dd1f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take onlu the following columns\n",
    "features = [\n",
    "    \"duration\", \n",
    "    \"src_bytes\", \"dst_bytes\", \n",
    "    \"src_pkts\", \"dst_pkts\",\n",
    "    \"src_ip_bytes\", \"dst_ip_bytes\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"label\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd4ce016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>src_pkts</th>\n",
       "      <th>dst_pkts</th>\n",
       "      <th>src_ip_bytes</th>\n",
       "      <th>dst_ip_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80549.530260</td>\n",
       "      <td>1762852</td>\n",
       "      <td>41933215</td>\n",
       "      <td>252181</td>\n",
       "      <td>2</td>\n",
       "      <td>14911156</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000549</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration src_bytes  dst_bytes  src_pkts  dst_pkts  src_ip_bytes  \\\n",
       "0  80549.530260   1762852   41933215    252181         2      14911156   \n",
       "1      0.000000         0          0         1         0            63   \n",
       "2      0.000000         0          0         0         0             0   \n",
       "3      0.000000         0          0         0         0             0   \n",
       "4      0.000549         0        298         0         2             0   \n",
       "\n",
       "   dst_ip_bytes  \n",
       "0           236  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4           354  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "312a7c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: Int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c6d6956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13066/2898869028.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "for col in [\"duration\", \"src_bytes\", \"dst_bytes\", \"src_pkts\", \"dst_pkts\",\n",
    "            ]:\n",
    "    X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "\n",
    "# divide categorial and numerical columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93e20fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['duration', 'src_bytes', 'dst_bytes', 'src_pkts', 'dst_pkts', 'src_ip_bytes', 'dst_ip_bytes']\n",
      "Categorical columns: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Numerical columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d27b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    0.883291\n",
      "0    0.116709\n",
      "Name: proportion, dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "# Look at the distribution of the labels to check for class imbalance\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd042b",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "367918ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data processor\n",
    "processor = DataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3225c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Define the outer and inner cross-validation strategies\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecb4b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import kruskal\n",
    "import numpy as np\n",
    "\n",
    "# Define the Kruskal-Wallis score function for feature selection\n",
    "# This function computes the Kruskal-Wallis H statistic for each feature\n",
    "def kruskal_wallis_score(X, y):\n",
    "    scores = []\n",
    "    pvalues = []\n",
    "    for i in range(X.shape[1]):\n",
    "        groups = [X[y == cls, i] for cls in np.unique(y)]\n",
    "        try:\n",
    "            stat, p = kruskal(*groups)\n",
    "        except ValueError:\n",
    "            stat, p = 0, 1\n",
    "        scores.append(stat)\n",
    "        pvalues.append(p)\n",
    "    return np.array(scores), np.array(pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c730d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import kruskal\n",
    "import numpy as np\n",
    "\n",
    "# Define the Kruskal-Wallis score function for feature selection\n",
    "# This function computes the Kruskal-Wallis H statistic for each feature\n",
    "def kruskal_wallis_score(X, y):\n",
    "    scores = []\n",
    "    pvalues = []\n",
    "    for i in range(X.shape[1]):\n",
    "        groups = [X[y == cls, i] for cls in np.unique(y)]\n",
    "        try:\n",
    "            stat, p = kruskal(*groups)\n",
    "        except ValueError:\n",
    "            stat, p = 0, 1\n",
    "        scores.append(stat)\n",
    "        pvalues.append(p)\n",
    "    return np.array(scores), np.array(pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c0c5aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Feature Selector: anova...\n",
      "\n",
      " Testing Model: XGBoost...\n",
      "\n",
      " Testing Model: RandomForest...\n",
      "\n",
      " Testing Model: MLPClassifier...\n",
      "\n",
      "Testing Feature Selector: kruskal...\n",
      "\n",
      " Testing Model: XGBoost...\n",
      "\n",
      " Testing Model: RandomForest...\n",
      "\n",
      " Testing Model: MLPClassifier...\n",
      "\n",
      "Final Results:\n",
      "                  Modelo             F1        ROC-AUC          AUPRC  \\\n",
      "0          XGBoost_anova  0.999 ± 0.000  0.999 ± 0.000  1.000 ± 0.000   \n",
      "1     RandomForest_anova  1.000 ± 0.000  1.000 ± 0.000  1.000 ± 0.000   \n",
      "2    MLPClassifier_anova  0.998 ± 0.000  0.999 ± 0.000  1.000 ± 0.000   \n",
      "3        XGBoost_kruskal  0.999 ± 0.000  0.999 ± 0.000  1.000 ± 0.000   \n",
      "4   RandomForest_kruskal  1.000 ± 0.000  1.000 ± 0.000  1.000 ± 0.000   \n",
      "5  MLPClassifier_kruskal  0.998 ± 0.000  0.999 ± 0.000  1.000 ± 0.000   \n",
      "\n",
      "             MCC          Brier            FNR     TrainTime (s)  \\\n",
      "0  0.995 ± 0.000  0.001 ± 0.000  0.001 ± 0.000      26.69 ± 0.89   \n",
      "1  0.998 ± 0.000  0.000 ± 0.000  0.000 ± 0.000    254.59 ± 44.24   \n",
      "2  0.984 ± 0.001  0.003 ± 0.000  0.001 ± 0.000  1988.96 ± 220.58   \n",
      "3  0.995 ± 0.000  0.001 ± 0.000  0.001 ± 0.000      25.30 ± 0.54   \n",
      "4  0.998 ± 0.000  0.000 ± 0.000  0.000 ± 0.000     228.81 ± 9.38   \n",
      "5  0.985 ± 0.000  0.003 ± 0.000  0.001 ± 0.000  2135.04 ± 202.21   \n",
      "\n",
      "      ModelSize (KB)  \n",
      "0        627.1 ± 4.8  \n",
      "1  24086.9 ± 10069.3  \n",
      "2         37.9 ± 2.7  \n",
      "3        627.1 ± 4.8  \n",
      "4    30657.2 ± 753.6  \n",
      "5         40.0 ± 0.2  \n",
      "\n",
      "XGBoost_anova (anova)\n",
      "Features más seleccionadas:\n",
      "num__duration        3\n",
      "num__src_bytes       3\n",
      "num__dst_bytes       3\n",
      "num__src_pkts        3\n",
      "num__dst_pkts        3\n",
      "num__src_ip_bytes    3\n",
      "num__dst_ip_bytes    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RandomForest_anova (anova)\n",
      "Features más seleccionadas:\n",
      "num__duration        3\n",
      "num__src_bytes       3\n",
      "num__dst_bytes       3\n",
      "num__src_pkts        3\n",
      "num__dst_pkts        3\n",
      "num__src_ip_bytes    3\n",
      "num__dst_ip_bytes    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MLPClassifier_anova (anova)\n",
      "Features más seleccionadas:\n",
      "num__duration        3\n",
      "num__dst_bytes       3\n",
      "num__src_pkts        3\n",
      "num__src_ip_bytes    3\n",
      "num__dst_pkts        3\n",
      "num__src_bytes       2\n",
      "num__dst_ip_bytes    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "XGBoost_kruskal (kruskal)\n",
      "Features más seleccionadas:\n",
      "num__duration        3\n",
      "num__src_bytes       3\n",
      "num__dst_bytes       3\n",
      "num__src_pkts        3\n",
      "num__dst_pkts        3\n",
      "num__src_ip_bytes    3\n",
      "num__dst_ip_bytes    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RandomForest_kruskal (kruskal)\n",
      "Features más seleccionadas:\n",
      "num__duration        3\n",
      "num__src_bytes       3\n",
      "num__dst_bytes       3\n",
      "num__src_pkts        3\n",
      "num__dst_pkts        3\n",
      "num__src_ip_bytes    3\n",
      "num__dst_ip_bytes    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MLPClassifier_kruskal (kruskal)\n",
      "Features más seleccionadas:\n",
      "num__duration        3\n",
      "num__src_bytes       3\n",
      "num__dst_bytes       3\n",
      "num__src_pkts        3\n",
      "num__dst_pkts        3\n",
      "num__src_ip_bytes    3\n",
      "num__dst_ip_bytes    3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn.metrics import matthews_corrcoef, brier_score_loss, confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
    "import time, sys\n",
    "import joblib, os\n",
    "from sklearn.base import clone\n",
    "import pickle\n",
    "\n",
    "# Define the feature selectors\n",
    "feature_selectors = {\n",
    "    \"anova\": SelectKBest(score_func=f_classif),\n",
    "    \"kruskal\": SelectKBest(score_func=kruskal_wallis_score)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": {\n",
    "        \"estimator\": XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__max_depth\": [5, None],\n",
    "            \"clf__learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"estimator\": RandomForestClassifier(),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__max_depth\": [None, 10]\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"estimator\": MLPClassifier(max_iter=300, random_state=42),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__hidden_layer_sizes\": [(50,), (100,)],\n",
    "            \"clf__activation\": [\"relu\"],\n",
    "            \"clf__alpha\": [0.0001, 0.001]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "preds = {}\n",
    "for selector in feature_selectors.keys():\n",
    "    print(f\"\\nTesting Feature Selector: {selector}...\")\n",
    "    selector_instance = feature_selectors[selector]\n",
    "\n",
    "    for model, configuration in models.items():\n",
    "        print(f\"\\n Testing Model: {model}...\")\n",
    "        estimator = configuration[\"estimator\"]\n",
    "        param_grid = configuration[\"param_grid\"]\n",
    "\n",
    "        outer_scores = {\"f1\": [], \"roc_auc\": [], \"auprc\": [], \"mcc\": [], \n",
    "                        \"brier\": [], \"fnr\": [], \"training_time\": [], \"size\": []}\n",
    "        best_params_folds, best_features_folds = [], []\n",
    "        confusion_matrixes, classification_reports = [], []\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            pipe = Pipeline([\n",
    "                (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "                (\"select\", clone(selector_instance)),\n",
    "                (\"clf\", estimator)\n",
    "            ])\n",
    "\n",
    "            search = RandomizedSearchCV(\n",
    "                pipe,\n",
    "                param_distributions=param_grid,\n",
    "                n_iter=8,                  # menos combinaciones\n",
    "                scoring=\"f1\",\n",
    "                cv=inner_cv,               # inner_cv reducido (3)\n",
    "                n_jobs=-1,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            search.fit(X_train, y_train)\n",
    "            train_time = time.perf_counter() - start\n",
    "\n",
    "            best_model = search.best_estimator_\n",
    "            best_params_folds.append(search.best_params_)\n",
    "\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            if f\"{model}_{selector}\" not in preds:\n",
    "                preds[f\"{model}_{selector}\"] = np.zeros_like(y)\n",
    "\n",
    "            preds[f\"{model}_{selector}\"][test_idx] = y_pred\n",
    "\n",
    "            y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # Metrics\n",
    "            outer_scores[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "            outer_scores[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "            outer_scores[\"auprc\"].append(average_precision_score(y_test, y_proba))\n",
    "            outer_scores[\"mcc\"].append(matthews_corrcoef(y_test, y_pred))\n",
    "            outer_scores[\"brier\"].append(brier_score_loss(y_test, y_proba))\n",
    "            outer_scores[\"training_time\"].append(train_time)\n",
    "\n",
    "            # Best Features\n",
    "            select_step = best_model.named_steps[\"select\"]\n",
    "            feature_names = best_model.named_steps[\"pre\"].get_feature_names_out()\n",
    "            selected_mask = select_step.get_support()\n",
    "            selected_features = feature_names[selected_mask]\n",
    "            best_features_folds.append(list(selected_features))\n",
    "\n",
    "            # Confusion matrix & report\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "            outer_scores[\"fnr\"].append(fnr)\n",
    "            confusion_matrixes.append(cm)\n",
    "\n",
    "            report = classification_report(\n",
    "                y_test, y_pred,\n",
    "                target_names=[\"Benigno (0)\", \"Malicioso (1)\"],\n",
    "                output_dict=True\n",
    "            )\n",
    "            classification_reports.append(report)\n",
    "\n",
    "            size_bytes = sys.getsizeof(pickle.dumps(best_model))\n",
    "            outer_scores[\"size\"].append(size_bytes / 1024)\n",
    "\n",
    "        results.append({\n",
    "            \"Modelo\": f\"{model}_{selector}\",\n",
    "            \"F1\": f\"{np.mean(outer_scores['f1']):.3f} ± {np.std(outer_scores['f1']):.3f}\",\n",
    "            \"ROC-AUC\": f\"{np.mean(outer_scores['roc_auc']):.3f} ± {np.std(outer_scores['roc_auc']):.3f}\",\n",
    "            \"AUPRC\": f\"{np.mean(outer_scores['auprc']):.3f} ± {np.std(outer_scores['auprc']):.3f}\",\n",
    "            \"MCC\": f\"{np.mean(outer_scores['mcc']):.3f} ± {np.std(outer_scores['mcc']):.3f}\",\n",
    "            \"Brier\": f\"{np.mean(outer_scores['brier']):.3f} ± {np.std(outer_scores['brier']):.3f}\",\n",
    "            \"FNR\": f\"{np.mean(outer_scores['fnr']):.3f} ± {np.std(outer_scores['fnr']):.3f}\",\n",
    "            \"TrainTime (s)\": f\"{np.mean(outer_scores['training_time']):.2f} ± {np.std(outer_scores['training_time']):.2f}\",\n",
    "            \"ModelSize (KB)\": f\"{np.mean(outer_scores['size']):.1f} ± {np.std(outer_scores['size']):.1f}\",\n",
    "            \"FeatureSelector\": selector,\n",
    "            \"BestParams_por_fold\": best_params_folds,\n",
    "            \"BestFeatures_por_fold\": best_features_folds,\n",
    "            \"ConfusionMatrix_por_fold\": confusion_matrixes,\n",
    "            \"ClassificationReport_por_fold\": classification_reports\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    selector = row[\"FeatureSelector\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "\n",
    "    print(f\"\\n{modelo} ({selector})\")\n",
    "    print(\"Features más seleccionadas:\")\n",
    "    print(feat_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7241a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "                  Modelo             F1        ROC-AUC          AUPRC  \\\n",
      "0          XGBoost_anova  0.999 ± 0.000  0.999 ± 0.000  1.000 ± 0.000   \n",
      "1     RandomForest_anova  1.000 ± 0.000  1.000 ± 0.000  1.000 ± 0.000   \n",
      "2    MLPClassifier_anova  0.998 ± 0.000  0.999 ± 0.000  1.000 ± 0.000   \n",
      "3        XGBoost_kruskal  0.999 ± 0.000  0.999 ± 0.000  1.000 ± 0.000   \n",
      "4   RandomForest_kruskal  1.000 ± 0.000  1.000 ± 0.000  1.000 ± 0.000   \n",
      "5  MLPClassifier_kruskal  0.998 ± 0.000  0.999 ± 0.000  1.000 ± 0.000   \n",
      "\n",
      "             MCC          Brier            FNR     TrainTime (s)  \\\n",
      "0  0.995 ± 0.000  0.001 ± 0.000  0.001 ± 0.000      26.69 ± 0.89   \n",
      "1  0.998 ± 0.000  0.000 ± 0.000  0.000 ± 0.000    254.59 ± 44.24   \n",
      "2  0.984 ± 0.001  0.003 ± 0.000  0.001 ± 0.000  1988.96 ± 220.58   \n",
      "3  0.995 ± 0.000  0.001 ± 0.000  0.001 ± 0.000      25.30 ± 0.54   \n",
      "4  0.998 ± 0.000  0.000 ± 0.000  0.000 ± 0.000     228.81 ± 9.38   \n",
      "5  0.985 ± 0.000  0.003 ± 0.000  0.001 ± 0.000  2135.04 ± 202.21   \n",
      "\n",
      "      ModelSize (KB)  \n",
      "0        627.1 ± 4.8  \n",
      "1  24086.9 ± 10069.3  \n",
      "2         37.9 ± 2.7  \n",
      "3        627.1 ± 4.8  \n",
      "4    30657.2 ± 753.6  \n",
      "5         40.0 ± 0.2  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Results:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55b38ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Modelo 1               Modelo 2 Estadístico  p-valor\n",
      "0         XGBoost_anova     RandomForest_anova     860.928  0.00000\n",
      "1         XGBoost_anova    MLPClassifier_anova    3695.376  0.00000\n",
      "2    RandomForest_anova    MLPClassifier_anova    5189.309  0.00000\n",
      "3       XGBoost_kruskal   RandomForest_kruskal     846.523  0.00000\n",
      "4       XGBoost_kruskal  MLPClassifier_kruskal    3439.049  0.00000\n",
      "5  RandomForest_kruskal  MLPClassifier_kruskal    4908.621  0.00000\n",
      "6         XGBoost_anova        XGBoost_kruskal         inf  0.00000\n",
      "7    RandomForest_anova   RandomForest_kruskal       0.302  0.58270\n",
      "8   MLPClassifier_anova  MLPClassifier_kruskal     108.006  0.00000\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def mcnemar_test(y_true, preds1, preds2):\n",
    "    b = np.sum((preds1 == y_true) & (preds2 != y_true))\n",
    "    c = np.sum((preds1 != y_true) & (preds2 == y_true))\n",
    "    table = [[0, b],[c, 0]]\n",
    "    result = mcnemar(table, exact=False, correction=True)\n",
    "    return result.statistic, result.pvalue\n",
    "\n",
    "\n",
    "pairs = [\n",
    "    (\"XGBoost_anova\", \"RandomForest_anova\"),\n",
    "    (\"XGBoost_anova\", \"MLPClassifier_anova\"),\n",
    "    (\"RandomForest_anova\", \"MLPClassifier_anova\"),\n",
    "    (\"XGBoost_kruskal\", \"RandomForest_kruskal\"),\n",
    "    (\"XGBoost_kruskal\", \"MLPClassifier_kruskal\"),\n",
    "    (\"RandomForest_kruskal\", \"MLPClassifier_kruskal\"),\n",
    "    (\"XGBoost_anova\", \"XGBoost_kruskal\"),\n",
    "    (\"RandomForest_anova\", \"RandomForest_kruskal\"),\n",
    "    (\"MLPClassifier_anova\", \"MLPClassifier_kruskal\")\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for m1, m2 in pairs:\n",
    "    stat, pval = mcnemar_test(y, preds[m1], preds[m2])\n",
    "    rows.append({\"Modelo 1\": m1, \"Modelo 2\": m2,\n",
    "                 \"Estadístico\": f\"{stat:.3f}\", \"p-valor\": f\"{pval:.5f}\"})\n",
    "\n",
    "df_mcnemar = pd.DataFrame(rows)\n",
    "print(df_mcnemar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0462535",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e5cff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcbbc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"duration\",\"src_bytes\",\"dst_bytes\",\n",
    "                \"src_pkts\",\"dst_pkts\",\"src_ip_bytes\",\"dst_ip_bytes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac68d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_features:\n",
    "    df_prep[col] = pd.to_numeric(df_prep[col], errors=\"coerce\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e611029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df_prep[num_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62b00f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = np.array(X_num)\n",
    "\n",
    "X_all = np.hstack([X_num,])\n",
    "\n",
    "y_all = df_prep[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7aef0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape secuencias: (1999990, 10, 7) (1999990,)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(X, y, window_size=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - window_size):\n",
    "        Xs.append(X[i:(i + window_size)])\n",
    "        ys.append(y[i + window_size])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_all, y_all, window_size=10)\n",
    "\n",
    "print(\"Shape secuencias:\", X_seq.shape, y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f5def0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.int64(233408), np.int64(1): np.int64(1766582)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y_seq, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1355342",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e32054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 01:14:11.340935: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-03 01:14:11.346420: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-03 01:14:11.740055: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-03 01:14:13.242901: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-03 01:14:13.243419: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo GRU_simple con balanceo class_weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 01:14:13.800953: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\n",
      "Entrenando modelo GRU_simple con balanceo oversampling...\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\n",
      "Entrenando modelo GRU_simple con balanceo smote...\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\n",
      "Entrenando modelo GRU_deep con balanceo class_weights...\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
      "\n",
      "Entrenando modelo GRU_deep con balanceo oversampling...\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
      "\n",
      "Entrenando modelo GRU_deep con balanceo smote...\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
      "\n",
      "Entrenando modelo GRU_focal con balanceo class_weights...\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\n",
      "Entrenando modelo GRU_focal con balanceo oversampling...\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\n",
      "Entrenando modelo GRU_focal con balanceo smote...\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os, joblib, tensorflow as tf\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, matthews_corrcoef, brier_score_loss, confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def apply_class_weights(y_train):\n",
    "    classes = np.unique(y_train)\n",
    "    weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "    return dict(zip(classes, weights))\n",
    "\n",
    "def apply_oversampling(X_train, y_train):\n",
    "    X_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    df_train = pd.DataFrame(X_flat)\n",
    "    df_train[\"label\"] = y_train\n",
    "    df_majority = df_train[df_train.label == 1]\n",
    "    df_minority = df_train[df_train.label == 0]\n",
    "    df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "    df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "    y_bal = df_balanced[\"label\"].values\n",
    "    X_bal = df_balanced.drop(columns=[\"label\"]).values.reshape(-1, X_train.shape[1], X_train.shape[2])\n",
    "    return X_bal, y_bal\n",
    "\n",
    "def apply_smote(X_train, y_train):\n",
    "    n_samples, timesteps, n_features = X_train.shape\n",
    "    X_flat = X_train.reshape((n_samples, timesteps * n_features))\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_bal, y_bal = smote.fit_resample(X_flat, y_train)\n",
    "    X_bal = X_bal.reshape((-1, timesteps, n_features))\n",
    "    return X_bal, y_bal\n",
    "\n",
    "def build_gru_simple(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(64, input_shape=input_shape),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_gru_deep(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.3, input_shape=input_shape),\n",
    "        GRU(32, dropout=0.3, recurrent_dropout=0.3),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
    "    return model\n",
    "\n",
    "def build_gru_focal(input_shape):\n",
    "    def focal_loss(gamma=2., alpha=0.75):\n",
    "        def loss(y_true, y_pred):\n",
    "            y_true = tf.cast(y_true, tf.float32)\n",
    "            bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "            pt = tf.exp(-bce)\n",
    "            return alpha * (1 - pt) ** gamma * bce\n",
    "        return loss\n",
    "    model = Sequential([\n",
    "        GRU(64, input_shape=input_shape),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(1e-3), loss=focal_loss(), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "architectures = {\n",
    "    \"GRU_simple\": build_gru_simple,\n",
    "    \"GRU_deep\": build_gru_deep,\n",
    "    \"GRU_focal\": build_gru_focal\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for arch_name, arch_func in architectures.items():\n",
    "    for balance_mode in [\"class_weights\", \"oversampling\", \"smote\"]:\n",
    "        print(f\"\\nEntrenando modelo {arch_name} con balanceo {balance_mode}...\")\n",
    "\n",
    "        X_train_bal, y_train_bal, cw = X_train, y_train, None\n",
    "\n",
    "        if balance_mode == \"class_weights\":\n",
    "            cw = apply_class_weights(y_train)\n",
    "        elif balance_mode == \"oversampling\":\n",
    "            X_train_bal, y_train_bal = apply_oversampling(X_train, y_train)\n",
    "            cw = apply_class_weights(y_train_bal)\n",
    "        elif balance_mode == \"smote\":\n",
    "            X_train_bal, y_train_bal = apply_smote(X_train, y_train)\n",
    "            cw = apply_class_weights(y_train_bal)\n",
    "\n",
    "        input_shape = (X_train_bal.shape[1], X_train_bal.shape[2])\n",
    "        model = arch_func(input_shape)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        history = model.fit(\n",
    "            X_train_bal, y_train_bal,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=10,\n",
    "            batch_size=256,\n",
    "            class_weight=cw,\n",
    "            verbose=0,\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)]\n",
    "        )\n",
    "        train_time = time.perf_counter() - start\n",
    "\n",
    "        y_proba = model.predict(X_test, batch_size=256).flatten()\n",
    "        y_pred = (y_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        auprc = average_precision_score(y_test, y_proba)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        brier = brier_score_loss(y_test, y_proba)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        fnr = fn / (fn + tp) if (fn+tp)>0 else 0\n",
    "\n",
    "        joblib.dump(model, \"tmp_gru_model.pkl\")\n",
    "        size_kb = os.path.getsize(\"tmp_gru_model.pkl\") / 1024\n",
    "        os.remove(\"tmp_gru_model.pkl\")\n",
    "\n",
    "        results.append({\n",
    "            \"Modelo\": arch_name,\n",
    "            \"Balanceo\": balance_mode,\n",
    "            \"F1\": f\"{f1:.3f}\",\n",
    "            \"ROC-AUC\": f\"{roc_auc:.3f}\",\n",
    "            \"AUPRC\": f\"{auprc:.3f}\",\n",
    "            \"MCC\": f\"{mcc:.3f}\",\n",
    "            \"Brier\": f\"{brier:.3f}\",\n",
    "            \"FNR\": f\"{fnr:.3f}\",\n",
    "            \"TrainTime (s)\": f\"{train_time:.2f}\",\n",
    "            \"ModelSize (KB)\": f\"{size_kb:.1f}\"\n",
    "        })\n",
    "\n",
    "df_gru = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8a6502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados finales GRU:\n",
      "       Modelo       Balanceo     F1 ROC-AUC  AUPRC    MCC  Brier    FNR  \\\n",
      "0  GRU_simple  class_weights  0.982   0.814  0.991  0.411  0.029  0.024   \n",
      "1  GRU_simple   oversampling  0.985   0.801  0.990  0.312  0.025  0.011   \n",
      "2  GRU_simple          smote  0.982   0.815  0.991  0.412  0.027  0.023   \n",
      "3    GRU_deep  class_weights  0.981   0.823  0.992  0.407  0.032  0.027   \n",
      "4    GRU_deep   oversampling  0.982   0.816  0.991  0.422  0.029  0.024   \n",
      "5    GRU_deep          smote  0.981   0.825  0.992  0.413  0.032  0.026   \n",
      "6   GRU_focal  class_weights  0.983   0.817  0.991  0.386  0.065  0.021   \n",
      "7   GRU_focal   oversampling  0.981   0.827  0.992  0.412  0.065  0.025   \n",
      "8   GRU_focal          smote  0.981   0.826  0.992  0.410  0.072  0.026   \n",
      "\n",
      "  TrainTime (s) ModelSize (KB)  \n",
      "0        448.34          188.8  \n",
      "1        352.09          188.8  \n",
      "2        634.96          188.8  \n",
      "3        597.44          326.4  \n",
      "4        771.22          326.4  \n",
      "5        890.60          326.4  \n",
      "6        412.01          188.9  \n",
      "7        745.83          188.9  \n",
      "8        743.29          188.9  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResultados finales GRU:\")\n",
    "print(df_gru)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
