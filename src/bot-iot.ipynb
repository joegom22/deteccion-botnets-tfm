{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e17c404",
   "metadata": {},
   "source": [
    "# Bot-IoT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7551bb4",
   "metadata": {},
   "source": [
    "## Carga y Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ed7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from DataProcessor import DataProcessor\n",
    "import pandas as pd\n",
    "\n",
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d0a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 02:58:08,180 - INFO - CSV file loaded successfully:           stime flgs proto            saddr   sport          daddr  dport  \\\n",
      "0  1.528083e+09  e s   tcp  192.168.100.150  5712.0  192.168.100.6   80.0   \n",
      "1  1.528083e+09  e s   tcp  192.168.100.150  5713.0  192.168.100.6   80.0   \n",
      "2  1.528083e+09  e s   tcp  192.168.100.150  5594.0  192.168.100.6   80.0   \n",
      "3  1.528083e+09  e s   tcp  192.168.100.150  5595.0  192.168.100.6   80.0   \n",
      "4  1.528083e+09  e s   tcp  192.168.100.150  5598.0  192.168.100.6   80.0   \n",
      "\n",
      "   pkts  bytes state  ...  spkts  dpkts  sbytes  dbytes      rate     srate  \\\n",
      "0     4    616   REQ  ...      4      0     616       0  0.050914  0.050914   \n",
      "1     4    616   REQ  ...      4      0     616       0  0.050914  0.050914   \n",
      "2     6    736   RST  ...      4      2     616     120  0.084802  0.050914   \n",
      "3     6    736   RST  ...      4      2     616     120  0.084802  0.050914   \n",
      "4     6    736   RST  ...      4      2     616     120  0.084802  0.050914   \n",
      "\n",
      "      drate  attack  category  subcategory   \n",
      "0  0.000000       1       DoS           TCP  \n",
      "1  0.000000       1       DoS           TCP  \n",
      "2  0.016972       1       DoS           TCP  \n",
      "3  0.016972       1       DoS           TCP  \n",
      "4  0.016973       1       DoS           TCP  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "df = loader.load_dataset('/home/joel/.cache/kagglehub/datasets/vigneshvenkateswaran/bot-iot/versions/1/data_10.csv', file_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0883dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stime</th>\n",
       "      <th>flgs</th>\n",
       "      <th>proto</th>\n",
       "      <th>saddr</th>\n",
       "      <th>sport</th>\n",
       "      <th>daddr</th>\n",
       "      <th>dport</th>\n",
       "      <th>pkts</th>\n",
       "      <th>bytes</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>srate</th>\n",
       "      <th>drate</th>\n",
       "      <th>attack</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528083e+09</td>\n",
       "      <td>e s</td>\n",
       "      <td>tcp</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>5712.0</td>\n",
       "      <td>192.168.100.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4</td>\n",
       "      <td>616</td>\n",
       "      <td>REQ</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.528083e+09</td>\n",
       "      <td>e s</td>\n",
       "      <td>tcp</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>5713.0</td>\n",
       "      <td>192.168.100.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4</td>\n",
       "      <td>616</td>\n",
       "      <td>REQ</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.528083e+09</td>\n",
       "      <td>e s</td>\n",
       "      <td>tcp</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>5594.0</td>\n",
       "      <td>192.168.100.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6</td>\n",
       "      <td>736</td>\n",
       "      <td>RST</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>616</td>\n",
       "      <td>120</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.528083e+09</td>\n",
       "      <td>e s</td>\n",
       "      <td>tcp</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>5595.0</td>\n",
       "      <td>192.168.100.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6</td>\n",
       "      <td>736</td>\n",
       "      <td>RST</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>616</td>\n",
       "      <td>120</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.528083e+09</td>\n",
       "      <td>e s</td>\n",
       "      <td>tcp</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>5598.0</td>\n",
       "      <td>192.168.100.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6</td>\n",
       "      <td>736</td>\n",
       "      <td>RST</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>616</td>\n",
       "      <td>120</td>\n",
       "      <td>0.084802</td>\n",
       "      <td>0.050914</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stime flgs proto            saddr   sport          daddr  dport  \\\n",
       "0  1.528083e+09  e s   tcp  192.168.100.150  5712.0  192.168.100.6   80.0   \n",
       "1  1.528083e+09  e s   tcp  192.168.100.150  5713.0  192.168.100.6   80.0   \n",
       "2  1.528083e+09  e s   tcp  192.168.100.150  5594.0  192.168.100.6   80.0   \n",
       "3  1.528083e+09  e s   tcp  192.168.100.150  5595.0  192.168.100.6   80.0   \n",
       "4  1.528083e+09  e s   tcp  192.168.100.150  5598.0  192.168.100.6   80.0   \n",
       "\n",
       "   pkts  bytes state  ...  spkts  dpkts  sbytes  dbytes      rate     srate  \\\n",
       "0     4    616   REQ  ...      4      0     616       0  0.050914  0.050914   \n",
       "1     4    616   REQ  ...      4      0     616       0  0.050914  0.050914   \n",
       "2     6    736   RST  ...      4      2     616     120  0.084802  0.050914   \n",
       "3     6    736   RST  ...      4      2     616     120  0.084802  0.050914   \n",
       "4     6    736   RST  ...      4      2     616     120  0.084802  0.050914   \n",
       "\n",
       "      drate  attack  category  subcategory   \n",
       "0  0.000000       1       DoS           TCP  \n",
       "1  0.000000       1       DoS           TCP  \n",
       "2  0.016972       1       DoS           TCP  \n",
       "3  0.016972       1       DoS           TCP  \n",
       "4  0.016973       1       DoS           TCP  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b4ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 34 columns):\n",
      " #   Column        Non-Null Count    Dtype  \n",
      "---  ------        --------------    -----  \n",
      " 0   stime         1000000 non-null  float64\n",
      " 1   flgs          1000000 non-null  object \n",
      " 2   proto         1000000 non-null  object \n",
      " 3   saddr         1000000 non-null  object \n",
      " 4   sport         999971 non-null   float64\n",
      " 5   daddr         1000000 non-null  object \n",
      " 6   dport         999971 non-null   float64\n",
      " 7   pkts          1000000 non-null  int64  \n",
      " 8   bytes         1000000 non-null  int64  \n",
      " 9   state         1000000 non-null  object \n",
      " 10  ltime         1000000 non-null  float64\n",
      " 11  seq           1000000 non-null  int64  \n",
      " 12  dur           1000000 non-null  float64\n",
      " 13  mean          1000000 non-null  float64\n",
      " 14  stddev        1000000 non-null  float64\n",
      " 15  smac          0 non-null        float64\n",
      " 16  dmac          0 non-null        float64\n",
      " 17  sum           1000000 non-null  float64\n",
      " 18  min           1000000 non-null  float64\n",
      " 19  max           1000000 non-null  float64\n",
      " 20  soui          0 non-null        float64\n",
      " 21  doui          0 non-null        float64\n",
      " 22  sco           0 non-null        float64\n",
      " 23  dco           0 non-null        float64\n",
      " 24  spkts         1000000 non-null  int64  \n",
      " 25  dpkts         1000000 non-null  int64  \n",
      " 26  sbytes        1000000 non-null  int64  \n",
      " 27  dbytes        1000000 non-null  int64  \n",
      " 28  rate          1000000 non-null  float64\n",
      " 29  srate         1000000 non-null  float64\n",
      " 30  drate         1000000 non-null  float64\n",
      " 31  attack        1000000 non-null  int64  \n",
      " 32  category      1000000 non-null  object \n",
      " 33  subcategory   1000000 non-null  object \n",
      "dtypes: float64(19), int64(8), object(7)\n",
      "memory usage: 259.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f69aaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "DoS       0.99997\n",
       "Normal    0.00003\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e40ea2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "DoS       999970\n",
       "Normal        30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42f300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "features = [\"spkts\", \"dpkts\", \"sbytes\", \"dbytes\", \"dur\"]\n",
    "\n",
    "X = df[features].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "y = df[\"category\"].map(lambda x: 0 if x in [\"Normal\", 0] else 1)\n",
    "X = X.rename(columns={\n",
    "    \"spkts\": \"src_pkts\",\n",
    "    \"dpkts\": \"dst_pkts\",\n",
    "    \"sbytes\": \"src_bytes\",\n",
    "    \"dbytes\": \"dst_bytes\",\n",
    "    \"dur\": \"duration\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58813772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_pkts</th>\n",
       "      <th>dst_pkts</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>58.922619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>58.922619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>616</td>\n",
       "      <td>120</td>\n",
       "      <td>58.960598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>616</td>\n",
       "      <td>120</td>\n",
       "      <td>58.960598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>616</td>\n",
       "      <td>120</td>\n",
       "      <td>58.960598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src_pkts  dst_pkts  src_bytes  dst_bytes   duration\n",
       "0         4         0        616          0  58.922619\n",
       "1         4         0        616          0  58.922619\n",
       "2         4         2        616        120  58.960598\n",
       "3         4         2        616        120  58.960598\n",
       "4         4         2        616        120  58.960598"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c355b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc947ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"duration\", \"src_bytes\", \"dst_bytes\", \"src_pkts\", \"dst_pkts\",\n",
    "            ]:\n",
    "    X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "\n",
    "# divide categorial and numerical columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09a6ca",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267077ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data processor\n",
    "processor = DataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08b567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Define the outer and inner cross-validation strategies\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f999643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando XGBoost...\n",
      "\n",
      "Evaluando RandomForest...\n",
      "\n",
      "Evaluando MLPClassifier...\n",
      "\n",
      "Resultados finales:\n",
      "          Modelo             F1        ROC-AUC          AUPRC            MCC  \\\n",
      "0        XGBoost  1.000 Â± 0.000  0.998 Â± 0.001  1.000 Â± 0.000  0.854 Â± 0.056   \n",
      "1   RandomForest  1.000 Â± 0.000  0.983 Â± 0.024  1.000 Â± 0.000  0.931 Â± 0.026   \n",
      "2  MLPClassifier  1.000 Â± 0.000  1.000 Â± 0.000  1.000 Â± 0.000  0.823 Â± 0.052   \n",
      "\n",
      "           Brier            FNR TrainTime (s) ModelSize (KB)  \n",
      "0  0.000 Â± 0.000  0.000 Â± 0.000   0.91 Â± 0.06     89.6 Â± 0.4  \n",
      "1  0.000 Â± 0.000  0.000 Â± 0.000   5.89 Â± 0.23    152.1 Â± 2.5  \n",
      "2  0.000 Â± 0.000  0.000 Â± 0.000  12.50 Â± 0.23     21.6 Â± 0.0  \n",
      "\n",
      "XGBoost - Features mÃ¡s seleccionadas:\n",
      "num__src_pkts     3\n",
      "num__dst_pkts     3\n",
      "num__src_bytes    3\n",
      "num__dst_bytes    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RandomForest - Features mÃ¡s seleccionadas:\n",
      "num__src_pkts     3\n",
      "num__dst_pkts     3\n",
      "num__src_bytes    3\n",
      "num__dst_bytes    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MLPClassifier - Features mÃ¡s seleccionadas:\n",
      "num__src_pkts     3\n",
      "num__dst_pkts     3\n",
      "num__src_bytes    3\n",
      "num__dst_bytes    3\n",
      "num__duration     3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, brier_score_loss, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib, os\n",
    "\n",
    "best_models = {\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=4)),\n",
    "        (\"clf\", XGBClassifier(eval_metric=\"logloss\", n_estimators=100, max_depth=5, learning_rate=0.1))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=4)),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "    ]),\n",
    "    \"MLPClassifier\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=5)),\n",
    "        (\"clf\", MLPClassifier(hidden_layer_sizes=(50,), activation=\"relu\", alpha=0.0001, max_iter=500, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "preds = {}\n",
    "for model_name, pipeline in best_models.items():\n",
    "    print(f\"\\nEvaluando {model_name}...\")\n",
    "\n",
    "    outer_scores = {\"f1\": [], \"roc_auc\": [], \"auprc\": [], \"mcc\": [], \"brier\": [], \"fnr\": [], \"training_time\": [], \"size\": []}\n",
    "    confusion_matrixes, classification_reports = [], []\n",
    "    selected_features_folds = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(pipeline)\n",
    "        start = time.perf_counter()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.perf_counter() - start\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        if f\"{model_name}\" not in preds:\n",
    "            preds[f\"{model_name}\"] = np.zeros(len(y))\n",
    "\n",
    "        preds[f\"{model_name}\"][test_idx] = y_pred\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        outer_scores[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "        outer_scores[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "        outer_scores[\"auprc\"].append(average_precision_score(y_test, y_proba))\n",
    "        outer_scores[\"mcc\"].append(matthews_corrcoef(y_test, y_pred))\n",
    "        outer_scores[\"brier\"].append(brier_score_loss(y_test, y_proba))\n",
    "        outer_scores[\"training_time\"].append(train_time)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        outer_scores[\"fnr\"].append(fnr)\n",
    "        confusion_matrixes.append(cm)\n",
    "\n",
    "        report = classification_report(\n",
    "            y_test, y_pred,\n",
    "            target_names=[\"Benigno (0)\", \"Malicioso (1)\"],\n",
    "            output_dict=True\n",
    "        )\n",
    "        classification_reports.append(report)\n",
    "\n",
    "        select_step = model.named_steps[\"select\"]\n",
    "        feature_names = model.named_steps[\"pre\"].get_feature_names_out()\n",
    "        selected_mask = select_step.get_support()\n",
    "        selected_features = feature_names[selected_mask]\n",
    "        selected_features_folds.append(list(selected_features))\n",
    "\n",
    "        joblib.dump(model, \"tmp_best_model.pkl\")\n",
    "        size_bytes = os.path.getsize(\"tmp_best_model.pkl\")\n",
    "        outer_scores[\"size\"].append(size_bytes / 1024)\n",
    "        os.remove(\"tmp_best_model.pkl\")\n",
    "\n",
    "    results.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"F1\": f\"{np.mean(outer_scores['f1']):.3f} Â± {np.std(outer_scores['f1']):.3f}\",\n",
    "        \"ROC-AUC\": f\"{np.mean(outer_scores['roc_auc']):.3f} Â± {np.std(outer_scores['roc_auc']):.3f}\",\n",
    "        \"AUPRC\": f\"{np.mean(outer_scores['auprc']):.3f} Â± {np.std(outer_scores['auprc']):.3f}\",\n",
    "        \"MCC\": f\"{np.mean(outer_scores['mcc']):.3f} Â± {np.std(outer_scores['mcc']):.3f}\",\n",
    "        \"Brier\": f\"{np.mean(outer_scores['brier']):.3f} Â± {np.std(outer_scores['brier']):.3f}\",\n",
    "        \"FNR\": f\"{np.mean(outer_scores['fnr']):.3f} Â± {np.std(outer_scores['fnr']):.3f}\",\n",
    "        \"TrainTime (s)\": f\"{np.mean(outer_scores['training_time']):.2f} Â± {np.std(outer_scores['training_time']):.2f}\",\n",
    "        \"ModelSize (KB)\": f\"{np.mean(outer_scores['size']):.1f} Â± {np.std(outer_scores['size']):.1f}\",\n",
    "        \"ConfusionMatrix_por_fold\": confusion_matrixes,\n",
    "        \"ClassificationReport_por_fold\": classification_reports,\n",
    "        \"BestFeatures_por_fold\": selected_features_folds\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nResultados finales:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "    print(f\"\\n{modelo} - Features mÃ¡s seleccionadas:\")\n",
    "    print(feat_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92739ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Modelo 1       Modelo 2 EstadÃ­stico  p-valor\n",
      "0       XGBoost   RandomForest       2.250  0.13361\n",
      "1       XGBoost  MLPClassifier       0.500  0.47950\n",
      "2  RandomForest  MLPClassifier       4.167  0.04123\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def mcnemar_test(y_true, preds1, preds2):\n",
    "    b = np.sum((preds1 == y_true) & (preds2 != y_true))\n",
    "    c = np.sum((preds1 != y_true) & (preds2 == y_true))\n",
    "    table = [[0, b],[c, 0]]\n",
    "    result = mcnemar(table, exact=False, correction=True)\n",
    "    return result.statistic, result.pvalue\n",
    "\n",
    "\n",
    "\n",
    "pairs = [(\"XGBoost\",\"RandomForest\"),(\"XGBoost\",\"MLPClassifier\"),(\"RandomForest\",\"MLPClassifier\")]\n",
    "\n",
    "rows = []\n",
    "for m1, m2 in pairs:\n",
    "    stat, pval = mcnemar_test(y, preds[m1], preds[m2])\n",
    "    rows.append({\"Modelo 1\": m1, \"Modelo 2\": m2,\n",
    "                 \"EstadÃ­stico\": f\"{stat:.3f}\", \"p-valor\": f\"{pval:.5f}\"})\n",
    "\n",
    "df_mcnemar = pd.DataFrame(rows)\n",
    "print(df_mcnemar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24c253",
   "metadata": {},
   "source": [
    "# Cross Validation y UniÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ddd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 03:22:31,190 - INFO - CSV file loaded successfully:           src_ip  src_port         dst_ip  dst_port proto service  \\\n",
      "0    3.122.49.24      1883  192.168.1.152     52976   tcp       -   \n",
      "1   192.168.1.79     47260  192.168.1.255     15600   udp       -   \n",
      "2  192.168.1.152      1880  192.168.1.152     51782   tcp       -   \n",
      "3  192.168.1.152     34296  192.168.1.152     10502   tcp       -   \n",
      "4  192.168.1.152     46608  192.168.1.190        53   udp     dns   \n",
      "\n",
      "       duration src_bytes  dst_bytes conn_state  ...  http_response_body_len  \\\n",
      "0  80549.530260   1762852   41933215        OTH  ...                       0   \n",
      "1      0.000000         0          0         S0  ...                       0   \n",
      "2      0.000000         0          0        OTH  ...                       0   \n",
      "3      0.000000         0          0        OTH  ...                       0   \n",
      "4      0.000549         0        298        SHR  ...                       0   \n",
      "\n",
      "   http_status_code  http_user_agent  http_orig_mime_types  \\\n",
      "0                 0                -                     -   \n",
      "1                 0                -                     -   \n",
      "2                 0                -                     -   \n",
      "3                 0                -                     -   \n",
      "4                 0                -                     -   \n",
      "\n",
      "   http_resp_mime_types        weird_name  weird_addl  weird_notice  label  \\\n",
      "0                     -  bad_TCP_checksum           -             F      0   \n",
      "1                     -                 -           -             -      0   \n",
      "2                     -  bad_TCP_checksum           -             F      0   \n",
      "3                     -                 -           -             -      0   \n",
      "4                     -  bad_UDP_checksum           -             F      0   \n",
      "\n",
      "     type  \n",
      "0  normal  \n",
      "1  normal  \n",
      "2  normal  \n",
      "3  normal  \n",
      "4  normal  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "from DataLoader import DataLoader\n",
    "\n",
    "loader = DataLoader()\n",
    "\n",
    "df2 = loader.load_dataset('../data/1conn.log.labeled', file_type='zeek')\n",
    "\n",
    "df3 = loader.load_dataset(\"../data/Network_dataset_1.csv\", file_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b654dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "\n",
    "features2 = [\"orig_pkts\", \"resp_pkts\", \"orig_bytes\", \"resp_bytes\", \"duration\"]\n",
    "\n",
    "# Dataset Aposemat\n",
    "X2 = df2[features2].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "y2 = df2[\"label\"].map(lambda x: 0 if x in [\"Benign\"] else 1)\n",
    "\n",
    "# Renombrar columnas para unificarlas\n",
    "X2 = X2.rename(columns={\n",
    "    \"orig_pkts\": \"src_pkts\",\n",
    "    \"resp_pkts\": \"dst_pkts\",\n",
    "    \"orig_bytes\": \"src_bytes\",\n",
    "    \"resp_bytes\": \"dst_bytes\"\n",
    "})\n",
    "\n",
    "features3 = [\"src_pkts\", \"dst_pkts\", \"src_bytes\", \"dst_bytes\", \"duration\"]\n",
    "\n",
    "# Dataset TON_IoT\n",
    "x3 = df3[features3].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "y3 = df3[\"label\"]\n",
    "\n",
    "# Unir datasets\n",
    "Xjoined = pd.concat([x3, X2], ignore_index=True)\n",
    "yjoined = pd.concat([y3, y2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "062cca1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_pkts</th>\n",
       "      <th>dst_pkts</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252181</td>\n",
       "      <td>2</td>\n",
       "      <td>1762852.0</td>\n",
       "      <td>41933215</td>\n",
       "      <td>80549.530260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src_pkts  dst_pkts  src_bytes  dst_bytes      duration\n",
       "0    252181         2  1762852.0   41933215  80549.530260\n",
       "1         1         0        0.0          0      0.000000\n",
       "2         0         0        0.0          0      0.000000\n",
       "3         0         0        0.0          0      0.000000\n",
       "4         0         2        0.0        298      0.000549"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xjoined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11750bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yjoined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcf46f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    0.662499\n",
       "0    0.337501\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yjoined.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cbf6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando XGBoost...\n",
      "\n",
      "Evaluando RandomForest...\n",
      "\n",
      "Evaluando MLPClassifier...\n",
      "\n",
      "Resultados finales:\n",
      "          Modelo             F1        ROC-AUC          AUPRC            MCC  \\\n",
      "0        XGBoost  0.844 Â± 0.000  0.721 Â± 0.000  0.795 Â± 0.000  0.446 Â± 0.001   \n",
      "1   RandomForest  0.844 Â± 0.000  0.721 Â± 0.000  0.796 Â± 0.000  0.447 Â± 0.001   \n",
      "2  MLPClassifier  0.840 Â± 0.000  0.706 Â± 0.001  0.790 Â± 0.000  0.425 Â± 0.000   \n",
      "\n",
      "           Brier            FNR   TrainTime (s) ModelSize (KB)  \n",
      "0  0.167 Â± 0.000  0.000 Â± 0.000     2.34 Â± 0.27    313.6 Â± 3.2  \n",
      "1  0.167 Â± 0.000  0.000 Â± 0.000    19.80 Â± 0.21  3320.4 Â± 10.8  \n",
      "2  0.174 Â± 0.001  0.001 Â± 0.000  530.97 Â± 94.82     34.2 Â± 0.3  \n",
      "\n",
      "XGBoost - Features mÃ¡s seleccionadas:\n",
      "num__src_pkts     3\n",
      "num__dst_pkts     3\n",
      "num__src_bytes    3\n",
      "num__dst_bytes    3\n",
      "num__duration     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RandomForest - Features mÃ¡s seleccionadas:\n",
      "num__src_pkts     3\n",
      "num__dst_pkts     3\n",
      "num__src_bytes    3\n",
      "num__dst_bytes    3\n",
      "num__duration     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MLPClassifier - Features mÃ¡s seleccionadas:\n",
      "num__src_pkts     3\n",
      "num__dst_pkts     3\n",
      "num__src_bytes    3\n",
      "num__dst_bytes    3\n",
      "num__duration     3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, brier_score_loss, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib, os\n",
    "\n",
    "best_models = {\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=5)),\n",
    "        (\"clf\", XGBClassifier(eval_metric=\"logloss\", n_estimators=100, max_depth=None, learning_rate=0.05))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=5)),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2, random_state=42))\n",
    "    ]),\n",
    "    \"MLPClassifier\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=5)),\n",
    "        (\"clf\", MLPClassifier(hidden_layer_sizes=(100,), activation=\"relu\", alpha=0.0001, max_iter=500, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "preds = {}\n",
    "for model_name, pipeline in best_models.items():\n",
    "    print(f\"\\nEvaluando {model_name}...\")\n",
    "\n",
    "    outer_scores = {\"f1\": [], \"roc_auc\": [], \"auprc\": [], \"mcc\": [], \"brier\": [], \"fnr\": [], \"training_time\": [], \"size\": []}\n",
    "    confusion_matrixes, classification_reports = [], []\n",
    "    selected_features_folds = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(Xjoined, yjoined), 1):\n",
    "        X_train, X_test = Xjoined.iloc[train_idx], Xjoined.iloc[test_idx]\n",
    "        y_train, y_test = yjoined.iloc[train_idx], yjoined.iloc[test_idx]\n",
    "\n",
    "        model = clone(pipeline)\n",
    "        start = time.perf_counter()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.perf_counter() - start\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        if f\"{model_name}\" not in preds:\n",
    "            preds[f\"{model_name}\"] = np.zeros(len(yjoined))\n",
    "\n",
    "        preds[f\"{model_name}\"][test_idx] = y_pred\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        outer_scores[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "        outer_scores[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "        outer_scores[\"auprc\"].append(average_precision_score(y_test, y_proba))\n",
    "        outer_scores[\"mcc\"].append(matthews_corrcoef(y_test, y_pred))\n",
    "        outer_scores[\"brier\"].append(brier_score_loss(y_test, y_proba))\n",
    "        outer_scores[\"training_time\"].append(train_time)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        outer_scores[\"fnr\"].append(fnr)\n",
    "        confusion_matrixes.append(cm)\n",
    "\n",
    "        report = classification_report(\n",
    "            y_test, y_pred,\n",
    "            target_names=[\"Benigno (0)\", \"Malicioso (1)\"],\n",
    "            output_dict=True\n",
    "        )\n",
    "        classification_reports.append(report)\n",
    "\n",
    "        select_step = model.named_steps[\"select\"]\n",
    "        feature_names = model.named_steps[\"pre\"].get_feature_names_out()\n",
    "        selected_mask = select_step.get_support()\n",
    "        selected_features = feature_names[selected_mask]\n",
    "        selected_features_folds.append(list(selected_features))\n",
    "\n",
    "        joblib.dump(model, \"tmp_best_model.pkl\")\n",
    "        size_bytes = os.path.getsize(\"tmp_best_model.pkl\")\n",
    "        outer_scores[\"size\"].append(size_bytes / 1024)\n",
    "        os.remove(\"tmp_best_model.pkl\")\n",
    "\n",
    "    results.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"F1\": f\"{np.mean(outer_scores['f1']):.3f} Â± {np.std(outer_scores['f1']):.3f}\",\n",
    "        \"ROC-AUC\": f\"{np.mean(outer_scores['roc_auc']):.3f} Â± {np.std(outer_scores['roc_auc']):.3f}\",\n",
    "        \"AUPRC\": f\"{np.mean(outer_scores['auprc']):.3f} Â± {np.std(outer_scores['auprc']):.3f}\",\n",
    "        \"MCC\": f\"{np.mean(outer_scores['mcc']):.3f} Â± {np.std(outer_scores['mcc']):.3f}\",\n",
    "        \"Brier\": f\"{np.mean(outer_scores['brier']):.3f} Â± {np.std(outer_scores['brier']):.3f}\",\n",
    "        \"FNR\": f\"{np.mean(outer_scores['fnr']):.3f} Â± {np.std(outer_scores['fnr']):.3f}\",\n",
    "        \"TrainTime (s)\": f\"{np.mean(outer_scores['training_time']):.2f} Â± {np.std(outer_scores['training_time']):.2f}\",\n",
    "        \"ModelSize (KB)\": f\"{np.mean(outer_scores['size']):.1f} Â± {np.std(outer_scores['size']):.1f}\",\n",
    "        \"ConfusionMatrix_por_fold\": confusion_matrixes,\n",
    "        \"ClassificationReport_por_fold\": classification_reports,\n",
    "        \"BestFeatures_por_fold\": selected_features_folds\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nResultados finales:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "    print(f\"\\n{modelo} - Features mÃ¡s seleccionadas:\")\n",
    "    print(feat_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a3c3e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Modelo 1       Modelo 2 EstadÃ­stico  p-valor\n",
      "0       XGBoost   RandomForest     298.892  0.00000\n",
      "1       XGBoost  MLPClassifier   13796.420  0.00000\n",
      "2  RandomForest  MLPClassifier   14362.021  0.00000\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def mcnemar_test(y_true, preds1, preds2):\n",
    "    b = np.sum((preds1 == y_true) & (preds2 != y_true))\n",
    "    c = np.sum((preds1 != y_true) & (preds2 == y_true))\n",
    "    table = [[0, b],[c, 0]]\n",
    "    result = mcnemar(table, exact=False, correction=True)\n",
    "    return result.statistic, result.pvalue\n",
    "\n",
    "pairs = [(\"XGBoost\",\"RandomForest\"),(\"XGBoost\",\"MLPClassifier\"),(\"RandomForest\",\"MLPClassifier\")]\n",
    "\n",
    "rows = []\n",
    "for m1, m2 in pairs:\n",
    "    stat, pval = mcnemar_test(yjoined, preds[m1], preds[m2])\n",
    "    rows.append({\"Modelo 1\": m1, \"Modelo 2\": m2,\n",
    "                 \"EstadÃ­stico\": f\"{stat:.3f}\", \"p-valor\": f\"{pval:.5f}\"})\n",
    "\n",
    "df_mcnemar = pd.DataFrame(rows)\n",
    "print(df_mcnemar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d70631",
   "metadata": {},
   "source": [
    "### Entre Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67274248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando y evaluando XGBoost...\n",
      "\n",
      "Entrenando y evaluando RandomForest...\n",
      "\n",
      "Entrenando y evaluando MLPClassifier...\n",
      "\n",
      "Resultados finales:\n",
      "          Modelo     F1 ROC-AUC  AUPRC     MCC  Brier    FNR TrainTime (s)  \\\n",
      "0        XGBoost  0.015   0.453  1.000  -0.012  0.777  0.992          3.58   \n",
      "1   RandomForest  0.127   0.266  1.000  -0.004  0.811  0.932         48.98   \n",
      "2  MLPClassifier  0.000   0.800  1.000  -0.189  0.997  1.000        483.04   \n",
      "\n",
      "  ModelSize (KB)  \n",
      "0          216.1  \n",
      "1        43244.7  \n",
      "2           23.6  \n",
      "\n",
      "XGBoost - Features seleccionadas:\n",
      "num__src_pkts     1\n",
      "num__dst_pkts     1\n",
      "num__dst_bytes    1\n",
      "num__duration     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RandomForest - Features seleccionadas:\n",
      "num__src_pkts     1\n",
      "num__dst_pkts     1\n",
      "num__dst_bytes    1\n",
      "num__duration     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "MLPClassifier - Features seleccionadas:\n",
      "num__src_pkts     1\n",
      "num__dst_pkts     1\n",
      "num__src_bytes    1\n",
      "num__dst_bytes    1\n",
      "num__duration     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, brier_score_loss, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib, os\n",
    "\n",
    "best_models = {\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=4)),\n",
    "        (\"clf\", XGBClassifier(eval_metric=\"logloss\", n_estimators=100, max_depth=5, learning_rate=0.1))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=4)),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "    ]),\n",
    "    \"MLPClassifier\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=5)),\n",
    "        (\"clf\", MLPClassifier(hidden_layer_sizes=(50,), activation=\"relu\", alpha=0.0001, max_iter=500, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, pipeline in best_models.items():\n",
    "    print(f\"\\nEntrenando y evaluando {model_name}...\")\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    model = pipeline.fit(Xjoined, yjoined)\n",
    "    train_time = time.perf_counter() - start\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    roc_auc = roc_auc_score(y, y_proba)\n",
    "    auprc = average_precision_score(y, y_proba)\n",
    "    mcc = matthews_corrcoef(y, y_pred)\n",
    "    brier = brier_score_loss(y, y_proba)\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "    report = classification_report(\n",
    "        y, y_pred,\n",
    "        target_names=[\"Benigno (0)\", \"Malicioso (1)\"],\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    select_step = model.named_steps[\"select\"]\n",
    "    feature_names = model.named_steps[\"pre\"].get_feature_names_out()\n",
    "    selected_mask = select_step.get_support()\n",
    "    selected_features = feature_names[selected_mask]\n",
    "\n",
    "    joblib.dump(model, \"tmp_best_model.pkl\")\n",
    "    size_bytes = os.path.getsize(\"tmp_best_model.pkl\")\n",
    "    os.remove(\"tmp_best_model.pkl\")\n",
    "\n",
    "    results.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"F1\": f\"{f1:.3f}\",\n",
    "        \"ROC-AUC\": f\"{roc_auc:.3f}\",\n",
    "        \"AUPRC\": f\"{auprc:.3f}\",\n",
    "        \"MCC\": f\"{mcc:.3f}\",\n",
    "        \"Brier\": f\"{brier:.3f}\",\n",
    "        \"FNR\": f\"{fnr:.3f}\",\n",
    "        \"TrainTime (s)\": f\"{train_time:.2f}\",\n",
    "        \"ModelSize (KB)\": f\"{size_bytes/1024:.1f}\",\n",
    "        \"ConfusionMatrix\": cm,\n",
    "        \"ClassificationReport\": report,\n",
    "        \"BestFeatures\": list(selected_features)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nResultados finales:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    feats = pd.Series(row[\"BestFeatures\"]).value_counts()\n",
    "    print(f\"\\n{modelo} - Features seleccionadas:\")\n",
    "    print(feats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
