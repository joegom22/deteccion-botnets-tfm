{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4374f303",
   "metadata": {},
   "source": [
    "# APOSEMAT IOT-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e550614",
   "metadata": {},
   "source": [
    "### Carga y limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8309bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from DataProcessor import DataProcessor\n",
    "import pandas as pd\n",
    "\n",
    "Loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f965d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Zeek connection log with labels\n",
    "df1 = Loader.load_dataset(file_path=\"../data/1conn.log.labeled\", file_type=\"zeek\")\n",
    "df2 = Loader.load_dataset(file_path=\"../data/3conn.log.labeled\", file_type=\"zeek\")\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6081df1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>uid</th>\n",
       "      <th>id.orig_h</th>\n",
       "      <th>id.orig_p</th>\n",
       "      <th>id.resp_h</th>\n",
       "      <th>id.resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "      <th>label</th>\n",
       "      <th>detailed-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.525880e+09</td>\n",
       "      <td>CUmrqr4svHuSXJy5z7</td>\n",
       "      <td>192.168.100.103</td>\n",
       "      <td>51524</td>\n",
       "      <td>65.127.233.163</td>\n",
       "      <td>23</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.999051</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.525880e+09</td>\n",
       "      <td>CH98aB3s1kJeq6SFOc</td>\n",
       "      <td>192.168.100.103</td>\n",
       "      <td>56305</td>\n",
       "      <td>63.150.16.171</td>\n",
       "      <td>23</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.525880e+09</td>\n",
       "      <td>C3GBTkINvXNjVGtN5</td>\n",
       "      <td>192.168.100.103</td>\n",
       "      <td>41101</td>\n",
       "      <td>111.40.23.49</td>\n",
       "      <td>23</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.525880e+09</td>\n",
       "      <td>CDe43c1PtgynajGI6</td>\n",
       "      <td>192.168.100.103</td>\n",
       "      <td>60905</td>\n",
       "      <td>131.174.215.147</td>\n",
       "      <td>23</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.998796</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.525880e+09</td>\n",
       "      <td>CJaDcG3MZzvf1YVYI4</td>\n",
       "      <td>192.168.100.103</td>\n",
       "      <td>44301</td>\n",
       "      <td>91.42.47.63</td>\n",
       "      <td>23</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts                 uid        id.orig_h  id.orig_p  \\\n",
       "0  1.525880e+09  CUmrqr4svHuSXJy5z7  192.168.100.103      51524   \n",
       "1  1.525880e+09  CH98aB3s1kJeq6SFOc  192.168.100.103      56305   \n",
       "2  1.525880e+09   C3GBTkINvXNjVGtN5  192.168.100.103      41101   \n",
       "3  1.525880e+09   CDe43c1PtgynajGI6  192.168.100.103      60905   \n",
       "4  1.525880e+09  CJaDcG3MZzvf1YVYI4  192.168.100.103      44301   \n",
       "\n",
       "         id.resp_h  id.resp_p proto service  duration  orig_bytes  ...  \\\n",
       "0   65.127.233.163         23   tcp     NaN  2.999051           0  ...   \n",
       "1    63.150.16.171         23   tcp     NaN       NaN        <NA>  ...   \n",
       "2     111.40.23.49         23   tcp     NaN       NaN        <NA>  ...   \n",
       "3  131.174.215.147         23   tcp     NaN  2.998796           0  ...   \n",
       "4      91.42.47.63         23   tcp     NaN       NaN        <NA>  ...   \n",
       "\n",
       "   local_resp missed_bytes  history  orig_pkts  orig_ip_bytes resp_pkts  \\\n",
       "0        <NA>            0        S          3            180         0   \n",
       "1        <NA>            0        S          1             60         0   \n",
       "2        <NA>            0        S          1             60         0   \n",
       "3        <NA>            0        S          3            180         0   \n",
       "4        <NA>            0        S          1             60         0   \n",
       "\n",
       "   resp_ip_bytes  tunnel_parents      label             detailed-label  \n",
       "0              0        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "1              0        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "2              0        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "3              0        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "4              0        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8831bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1164851 entries, 0 to 1164850\n",
      "Data columns (total 23 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   ts              1164851 non-null  float64\n",
      " 1   uid             1164851 non-null  object \n",
      " 2   id.orig_h       1164851 non-null  object \n",
      " 3   id.orig_p       1164851 non-null  Int64  \n",
      " 4   id.resp_h       1164851 non-null  object \n",
      " 5   id.resp_p       1164851 non-null  Int64  \n",
      " 6   proto           1164851 non-null  object \n",
      " 7   service         9149 non-null     object \n",
      " 8   duration        294607 non-null   float64\n",
      " 9   orig_bytes      294607 non-null   Int64  \n",
      " 10  resp_bytes      294607 non-null   Int64  \n",
      " 11  conn_state      1164851 non-null  object \n",
      " 12  local_orig      0 non-null        boolean\n",
      " 13  local_resp      0 non-null        boolean\n",
      " 14  missed_bytes    1164851 non-null  Int64  \n",
      " 15  history         1146223 non-null  object \n",
      " 16  orig_pkts       1164851 non-null  Int64  \n",
      " 17  orig_ip_bytes   1164851 non-null  Int64  \n",
      " 18  resp_pkts       1164851 non-null  Int64  \n",
      " 19  resp_ip_bytes   1164851 non-null  Int64  \n",
      " 20  tunnel_parents  1164851 non-null  object \n",
      " 21  label           1164851 non-null  object \n",
      " 22  detailed-label  1164851 non-null  object \n",
      "dtypes: Int64(9), boolean(2), float64(2), object(10)\n",
      "memory usage: 201.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Observe the DataFrame structure and types to check for any inconsistencies\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ec83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 14:05:17,148 - INFO - Dataset cleaned successfully. 0 rows have been removed.\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset using the DataLoader's clean_dataset method that removes duplicates\n",
    "df = Loader.clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1ea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that could provide artificial patterns and prepare the features and labels\n",
    "drop_cols = [\"uid\", \"id.orig_h\", \"id.resp_h\", \"id.orig_p\", \"id.resp_p\",\n",
    "    \"tunnel_parents\", \"service\", \"history\", \"local_orig\", \"local_resp\", \"ts\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=drop_cols + [\"label\",\"detailed-label\"])\n",
    "y = df[\"label\"].map({\"Benign\":0, \"Malicious\":1}).astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca1d9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcp</td>\n",
       "      <td>2.999051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tcp</td>\n",
       "      <td>2.998796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  proto  duration  orig_bytes  resp_bytes conn_state  missed_bytes  orig_pkts  \\\n",
       "0   tcp  2.999051           0           0         S0             0          3   \n",
       "1   tcp       NaN        <NA>        <NA>         S0             0          1   \n",
       "2   tcp       NaN        <NA>        <NA>         S0             0          1   \n",
       "3   tcp  2.998796           0           0         S0             0          3   \n",
       "4   tcp       NaN        <NA>        <NA>         S0             0          1   \n",
       "\n",
       "   orig_ip_bytes  resp_pkts  resp_ip_bytes  \n",
       "0            180          0              0  \n",
       "1             60          0              0  \n",
       "2             60          0              0  \n",
       "3            180          0              0  \n",
       "4             60          0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few rows of the features DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f3cd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: Int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few rows of the labels Series\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98654094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    0.593243\n",
      "0    0.406757\n",
      "Name: proportion, dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "# Look at the distribution of the labels to check for class imbalance\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b96fd",
   "metadata": {},
   "source": [
    "### Nested Stratified KFold with SearchGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c94db418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the DataProcessor instance\n",
    "Processor = DataProcessor()\n",
    "\n",
    "# Get numerical and categorical columns from the DataFrame manually\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7e767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import kruskal\n",
    "import numpy as np\n",
    "\n",
    "# Define the Kruskal-Wallis score function for feature selection\n",
    "# This function computes the Kruskal-Wallis H statistic for each feature\n",
    "def kruskal_wallis_score(X, y):\n",
    "    scores = []\n",
    "    pvalues = []\n",
    "    for i in range(X.shape[1]):\n",
    "        groups = [X[y == cls, i] for cls in np.unique(y)]\n",
    "        try:\n",
    "            stat, p = kruskal(*groups)\n",
    "        except ValueError:\n",
    "            stat, p = 0, 1\n",
    "        scores.append(stat)\n",
    "        pvalues.append(p)\n",
    "    return np.array(scores), np.array(pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1973c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf1423bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [0, 21, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabadba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Define the outer and inner cross-validation strategies\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459ec859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Starting experiments with seed: 0\n",
      "\n",
      "Testing Feature Selector: anova...\n",
      "\n",
      " Testing Model: XGBoost...\n",
      "\n",
      " Testing Model: RandomForest...\n",
      "\n",
      " Testing Model: MLPClassifier...\n",
      "\n",
      "Testing Feature Selector: kruskal...\n",
      "\n",
      " Testing Model: XGBoost...\n",
      "\n",
      " Testing Model: RandomForest...\n",
      "\n",
      " Testing Model: MLPClassifier...\n",
      "\n",
      "\n",
      "\n",
      "Starting experiments with seed: 21\n",
      "\n",
      "Testing Feature Selector: anova...\n",
      "\n",
      " Testing Model: XGBoost...\n",
      "\n",
      " Testing Model: RandomForest...\n",
      "\n",
      " Testing Model: MLPClassifier...\n",
      "\n",
      "Testing Feature Selector: kruskal...\n",
      "\n",
      " Testing Model: XGBoost...\n",
      "\n",
      " Testing Model: RandomForest...\n",
      "\n",
      " Testing Model: MLPClassifier...\n",
      "\n",
      "\n",
      "\n",
      "Starting experiments with seed: 42\n",
      "\n",
      "Testing Feature Selector: anova...\n",
      "\n",
      " Testing Model: XGBoost...\n",
      "\n",
      " Testing Model: RandomForest...\n",
      "\n",
      " Testing Model: MLPClassifier...\n",
      "\n",
      "Testing Feature Selector: kruskal...\n",
      "\n",
      " Testing Model: XGBoost...\n",
      "\n",
      " Testing Model: RandomForest...\n",
      "\n",
      " Testing Model: MLPClassifier...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 180\u001b[0m\n\u001b[1;32m    174\u001b[0m     summary[metric] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    175\u001b[0m         summary[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;241m+\u001b[39m summary[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_std\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Seleccionar solo columnas resumidas\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m summary_final \u001b[38;5;241m=\u001b[39m \u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModelo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeatureSelector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mROC-AUC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAUPRC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMCC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBrier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFNR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainTime (s)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModelSize (KB)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResumen final sobre todas las seeds:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary_final\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/MasterIOT/deteccion-botnets-tfm/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4112\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4113\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4115\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/MasterIOT/deteccion-botnets-tfm/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6207\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6204\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(keyarr)\n\u001b[1;32m   6206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 6207\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6208\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex(keyarr)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/MasterIOT/deteccion-botnets-tfm/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6194\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   6176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6177\u001b[0m \u001b[38;5;124;03mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[1;32m   6178\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6191\u001b[0m \u001b[38;5;124;03marray([0, 2])\u001b[39;00m\n\u001b[1;32m   6192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 6194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6195\u001b[0m indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[0;32m~/MasterIOT/deteccion-botnets-tfm/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3960\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3955\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m this\u001b[38;5;241m.\u001b[39m_get_indexer(\n\u001b[1;32m   3957\u001b[0m         target, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[1;32m   3958\u001b[0m     )\n\u001b[0;32m-> 3960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MasterIOT/deteccion-botnets-tfm/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3987\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3985\u001b[0m         tgt_values \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_get_engine_target()\n\u001b[0;32m-> 3987\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:351\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7139\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn.metrics import matthews_corrcoef, brier_score_loss, confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
    "import time, sys\n",
    "import joblib, os\n",
    "from sklearn.base import clone\n",
    "import pickle\n",
    "\n",
    "# Define the feature selectors\n",
    "feature_selectors = {\n",
    "    \"anova\": SelectKBest(score_func=f_classif),\n",
    "    \"kruskal\": SelectKBest(score_func=kruskal_wallis_score)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": {\n",
    "        \"estimator\": XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__max_depth\": [5, None],\n",
    "            \"clf__learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"estimator\": RandomForestClassifier(),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__max_depth\": [None, 10]\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"estimator\": MLPClassifier(max_iter=300, random_state=42),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__hidden_layer_sizes\": [(50,), (100,)],\n",
    "            \"clf__activation\": [\"relu\"],\n",
    "            \"clf__alpha\": [0.0001, 0.001]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "preds = {}\n",
    "for selector in feature_selectors.keys():\n",
    "    print(f\"\\nTesting Feature Selector: {selector}...\")\n",
    "    selector_instance = feature_selectors[selector]\n",
    "\n",
    "    for model, configuration in models.items():\n",
    "        print(f\"\\n Testing Model: {model}...\")\n",
    "        estimator = configuration[\"estimator\"]\n",
    "        param_grid = configuration[\"param_grid\"]\n",
    "\n",
    "        outer_scores = {\"f1\": [], \"roc_auc\": [], \"auprc\": [], \"mcc\": [], \n",
    "                        \"brier\": [], \"fnr\": [], \"training_time\": [], \"size\": []}\n",
    "        best_params_folds, best_features_folds = [], []\n",
    "        confusion_matrixes, classification_reports = [], []\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            pipe = Pipeline([\n",
    "                (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "                (\"select\", clone(selector_instance)),\n",
    "                (\"clf\", estimator)\n",
    "            ])\n",
    "\n",
    "            search = RandomizedSearchCV(\n",
    "                pipe,\n",
    "                param_distributions=param_grid,\n",
    "                n_iter=8,\n",
    "                scoring=\"f1\",\n",
    "                cv=inner_cv,   \n",
    "                n_jobs=-1,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            search.fit(X_train, y_train)\n",
    "            train_time = time.perf_counter() - start\n",
    "\n",
    "            best_model = search.best_estimator_\n",
    "            best_params_folds.append(search.best_params_)\n",
    "\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            if f\"{model}_{selector}\" not in preds:\n",
    "                preds[f\"{model}_{selector}\"] = np.zeros_like(y)\n",
    "\n",
    "            preds[f\"{model}_{selector}\"][test_idx] = y_pred\n",
    "\n",
    "            y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # Metrics\n",
    "            outer_scores[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "            outer_scores[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "            outer_scores[\"auprc\"].append(average_precision_score(y_test, y_proba))\n",
    "            outer_scores[\"mcc\"].append(matthews_corrcoef(y_test, y_pred))\n",
    "            outer_scores[\"brier\"].append(brier_score_loss(y_test, y_proba))\n",
    "            outer_scores[\"training_time\"].append(train_time)\n",
    "\n",
    "            # Best Features\n",
    "            select_step = best_model.named_steps[\"select\"]\n",
    "            feature_names = best_model.named_steps[\"pre\"].get_feature_names_out()\n",
    "            selected_mask = select_step.get_support()\n",
    "            selected_features = feature_names[selected_mask]\n",
    "            best_features_folds.append(list(selected_features))\n",
    "\n",
    "            # Confusion matrix & report\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "            outer_scores[\"fnr\"].append(fnr)\n",
    "            confusion_matrixes.append(cm)\n",
    "\n",
    "            report = classification_report(\n",
    "                y_test, y_pred,\n",
    "                target_names=[\"Benigno (0)\", \"Malicioso (1)\"],\n",
    "                output_dict=True\n",
    "            )\n",
    "            classification_reports.append(report)\n",
    "\n",
    "            size_bytes = sys.getsizeof(pickle.dumps(best_model))\n",
    "            outer_scores[\"size\"].append(size_bytes / 1024)\n",
    "\n",
    "        results.append({\n",
    "            \"Modelo\": f\"{model}_{selector}\",\n",
    "            \"F1\": f\"{np.mean(outer_scores['f1']):.3f} ± {np.std(outer_scores['f1']):.3f}\",\n",
    "            \"ROC-AUC\": f\"{np.mean(outer_scores['roc_auc']):.3f} ± {np.std(outer_scores['roc_auc']):.3f}\",\n",
    "            \"AUPRC\": f\"{np.mean(outer_scores['auprc']):.3f} ± {np.std(outer_scores['auprc']):.3f}\",\n",
    "            \"MCC\": f\"{np.mean(outer_scores['mcc']):.3f} ± {np.std(outer_scores['mcc']):.3f}\",\n",
    "            \"Brier\": f\"{np.mean(outer_scores['brier']):.3f} ± {np.std(outer_scores['brier']):.3f}\",\n",
    "            \"FNR\": f\"{np.mean(outer_scores['fnr']):.3f} ± {np.std(outer_scores['fnr']):.3f}\",\n",
    "            \"TrainTime (s)\": f\"{np.mean(outer_scores['training_time']):.2f} ± {np.std(outer_scores['training_time']):.2f}\",\n",
    "            \"ModelSize (KB)\": f\"{np.mean(outer_scores['size']):.1f} ± {np.std(outer_scores['size']):.1f}\",\n",
    "            \"FeatureSelector\": selector,\n",
    "            \"BestParams_por_fold\": best_params_folds,\n",
    "            \"BestFeatures_por_fold\": best_features_folds,\n",
    "            \"ConfusionMatrix_por_fold\": confusion_matrixes,\n",
    "            \"ClassificationReport_por_fold\": classification_reports\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    selector = row[\"FeatureSelector\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "\n",
    "    print(f\"\\n{modelo} ({selector})\")\n",
    "    print(\"Features más seleccionadas:\")\n",
    "    print(feat_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d764303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFinal Results:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    selector = row[\"FeatureSelector\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "\n",
    "    print(f\"\\n{modelo} ({selector})\")\n",
    "    print(\"Features más seleccionadas:\")\n",
    "    print(feat_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a67011",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    best_params_list = row[\"BestParams_por_fold\"]\n",
    "\n",
    "    params_tuples = [tuple(sorted(d.items())) for d in best_params_list]\n",
    "    params_counts = pd.Series(params_tuples).value_counts()\n",
    "\n",
    "    print(f\"\\n{modelo}\")\n",
    "\n",
    "\n",
    "    best_overall = dict(params_counts.index[0])\n",
    "    print(\"=> Mejor configuración final:\", best_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, brier_score_loss, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "    (\"clf\", LogisticRegression(max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    \"clf__solver\": [\"lbfgs\", \"saga\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "search = RandomizedSearchCV(pipe, param_distributions=param_dist, n_iter=4,\n",
    "                            scoring=\"f1\", cv=cv, n_jobs=-1, random_state=42)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"F1: {f1_score(y_test, y_pred):.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "print(f\"AUPRC: {average_precision_score(y_test, y_proba):.3f}\")\n",
    "print(f\"MCC: {matthews_corrcoef(y_test, y_pred):.3f}\")\n",
    "print(f\"Brier: {brier_score_loss(y_test, y_proba):.3f}\")\n",
    "print(f\"FNR: {fnr:.3f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(\n",
    "    y_test, y_pred, target_names=[\"Benigno (0)\", \"Malicioso (1)\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=[\"conn_state\", \"missed_bytes\", \"proto\"], inplace=True)\n",
    "# Drop conn state, missed bytes and proto\n",
    "cat_cols.remove(\"conn_state\")\n",
    "num_cols.remove(\"missed_bytes\")\n",
    "cat_cols.remove(\"proto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f719ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn.metrics import matthews_corrcoef, brier_score_loss, confusion_matrix, classification_report\n",
    "import time, sys\n",
    "import joblib, os\n",
    "from sklearn.base import clone\n",
    "import pickle\n",
    "\n",
    "# Define the feature selectors\n",
    "feature_selectors = {\n",
    "    \"anova\": SelectKBest(score_func=f_classif),\n",
    "    \"kruskal\": SelectKBest(score_func=kruskal_wallis_score)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": {\n",
    "        \"estimator\": XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__max_depth\": [5, None],\n",
    "            \"clf__learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"estimator\": RandomForestClassifier(),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__n_estimators\": [100, 300],\n",
    "            \"clf__max_depth\": [None, 10]\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"estimator\": MLPClassifier(max_iter=300, random_state=42),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [5, 15],\n",
    "            \"clf__hidden_layer_sizes\": [(50,), (100,)],\n",
    "            \"clf__activation\": [\"relu\"],\n",
    "            \"clf__alpha\": [0.0001, 0.001]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "preds = {}\n",
    "for selector in feature_selectors.keys():\n",
    "    print(f\"\\nTesting Feature Selector: {selector}...\")\n",
    "    selector_instance = feature_selectors[selector]\n",
    "\n",
    "    for model, configuration in models.items():\n",
    "        print(f\"\\n Testing Model: {model}...\")\n",
    "        estimator = configuration[\"estimator\"]\n",
    "        param_grid = configuration[\"param_grid\"]\n",
    "\n",
    "        outer_scores = {\"f1\": [], \"roc_auc\": [], \"auprc\": [], \"mcc\": [], \n",
    "                        \"brier\": [], \"fnr\": [], \"training_time\": [], \"size\": []}\n",
    "        best_params_folds, best_features_folds = [], []\n",
    "        confusion_matrixes, classification_reports = [], []\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            pipe = Pipeline([\n",
    "                (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "                (\"select\", clone(selector_instance)),\n",
    "                (\"clf\", estimator)\n",
    "            ])\n",
    "\n",
    "            search = RandomizedSearchCV(\n",
    "                pipe,\n",
    "                param_distributions=param_grid,\n",
    "                n_iter=8,                  # menos combinaciones\n",
    "                scoring=\"f1\",\n",
    "                cv=inner_cv,               # inner_cv reducido (3)\n",
    "                n_jobs=-1,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            search.fit(X_train, y_train)\n",
    "            train_time = time.perf_counter() - start\n",
    "\n",
    "            best_model = search.best_estimator_\n",
    "            best_params_folds.append(search.best_params_)\n",
    "\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            if f\"{model}_{selector}\" not in preds:\n",
    "                preds[f\"{model}_{selector}\"] = np.zeros_like(y)\n",
    "\n",
    "            preds[f\"{model}_{selector}\"][test_idx] = y_pred\n",
    "\n",
    "            y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # Metrics\n",
    "            outer_scores[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "            outer_scores[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "            outer_scores[\"auprc\"].append(average_precision_score(y_test, y_proba))\n",
    "            outer_scores[\"mcc\"].append(matthews_corrcoef(y_test, y_pred))\n",
    "            outer_scores[\"brier\"].append(brier_score_loss(y_test, y_proba))\n",
    "            outer_scores[\"training_time\"].append(train_time)\n",
    "\n",
    "            # Best Features\n",
    "            select_step = best_model.named_steps[\"select\"]\n",
    "            feature_names = best_model.named_steps[\"pre\"].get_feature_names_out()\n",
    "            selected_mask = select_step.get_support()\n",
    "            selected_features = feature_names[selected_mask]\n",
    "            best_features_folds.append(list(selected_features))\n",
    "\n",
    "            # Confusion matrix & report\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "            outer_scores[\"fnr\"].append(fnr)\n",
    "            confusion_matrixes.append(cm)\n",
    "\n",
    "            report = classification_report(\n",
    "                y_test, y_pred,\n",
    "                target_names=[\"Benigno (0)\", \"Malicioso (1)\"],\n",
    "                output_dict=True\n",
    "            )\n",
    "            classification_reports.append(report)\n",
    "\n",
    "            size_bytes = sys.getsizeof(pickle.dumps(best_model))\n",
    "            outer_scores[\"size\"].append(size_bytes / 1024)\n",
    "\n",
    "        results.append({\n",
    "            \"Modelo\": f\"{model}_{selector}\",\n",
    "            \"F1\": f\"{np.mean(outer_scores['f1']):.3f} ± {np.std(outer_scores['f1']):.3f}\",\n",
    "            \"ROC-AUC\": f\"{np.mean(outer_scores['roc_auc']):.3f} ± {np.std(outer_scores['roc_auc']):.3f}\",\n",
    "            \"AUPRC\": f\"{np.mean(outer_scores['auprc']):.3f} ± {np.std(outer_scores['auprc']):.3f}\",\n",
    "            \"MCC\": f\"{np.mean(outer_scores['mcc']):.3f} ± {np.std(outer_scores['mcc']):.3f}\",\n",
    "            \"Brier\": f\"{np.mean(outer_scores['brier']):.3f} ± {np.std(outer_scores['brier']):.3f}\",\n",
    "            \"FNR\": f\"{np.mean(outer_scores['fnr']):.3f} ± {np.std(outer_scores['fnr']):.3f}\",\n",
    "            \"TrainTime (s)\": f\"{np.mean(outer_scores['training_time']):.2f} ± {np.std(outer_scores['training_time']):.2f}\",\n",
    "            \"ModelSize (KB)\": f\"{np.mean(outer_scores['size']):.1f} ± {np.std(outer_scores['size']):.1f}\",\n",
    "            \"FeatureSelector\": selector,\n",
    "            \"BestParams_por_fold\": best_params_folds,\n",
    "            \"BestFeatures_por_fold\": best_features_folds,\n",
    "            \"ConfusionMatrix_por_fold\": confusion_matrixes,\n",
    "            \"ClassificationReport_por_fold\": classification_reports\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    selector = row[\"FeatureSelector\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "\n",
    "    print(f\"\\n{modelo} ({selector})\")\n",
    "    print(\"Features más seleccionadas:\")\n",
    "    print(feat_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    selector = row[\"FeatureSelector\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "\n",
    "    print(f\"\\n{modelo} ({selector})\")\n",
    "    print(\"Features más seleccionadas:\")\n",
    "    print(feat_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11753695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def mcnemar_test(y_true, preds1, preds2):\n",
    "    b = np.sum((preds1 == y_true) & (preds2 != y_true))\n",
    "    c = np.sum((preds1 != y_true) & (preds2 == y_true))\n",
    "    table = [[0, b], [c, 0]]\n",
    "    result = mcnemar(table, exact=False, correction=True)\n",
    "    return result.statistic, result.pvalue\n",
    "\n",
    "\n",
    "pairs = [\n",
    "    (\"XGBoost_anova\", \"RandomForest_anova\"),\n",
    "    (\"XGBoost_anova\", \"MLPClassifier_anova\"),\n",
    "    (\"RandomForest_anova\", \"MLPClassifier_anova\"),\n",
    "    (\"XGBoost_kruskal\", \"RandomForest_kruskal\"),\n",
    "    (\"XGBoost_kruskal\", \"MLPClassifier_kruskal\"),\n",
    "    (\"RandomForest_kruskal\", \"MLPClassifier_kruskal\")\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for m1, m2 in pairs:\n",
    "    stat, pval = mcnemar_test(y, preds[m1], preds[m2])\n",
    "    rows.append({\"Modelo 1\": m1, \"Modelo 2\": m2,\n",
    "                 \"Estadístico\": f\"{stat:.3f}\", \"p-valor\": f\"{pval:.5f}\"})\n",
    "\n",
    "df_mcnemar = pd.DataFrame(rows)\n",
    "print(df_mcnemar)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
