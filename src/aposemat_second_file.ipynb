{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4374f303",
   "metadata": {},
   "source": [
    "# APOSEMAT IOT-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75ad452",
   "metadata": {},
   "source": [
    "## Segundo Fichero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e550614",
   "metadata": {},
   "source": [
    "### Carga y limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8309bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader\n",
    "from DataProcessor import DataProcessor\n",
    "import pandas as pd\n",
    "\n",
    "Loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f965d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Zeek connection log with labels\n",
    "df = Loader.load_dataset(file_path=\"C:/Users/PcVip/deteccion-botnets-tfm/data/conn.log.labeled\", file_type=\"zeek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6081df1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>uid</th>\n",
       "      <th>id.orig_h</th>\n",
       "      <th>id.orig_p</th>\n",
       "      <th>id.resp_h</th>\n",
       "      <th>id.resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "      <th>label</th>\n",
       "      <th>detailed-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>C9YvmJ3zxtuqxWxLW5</td>\n",
       "      <td>192.168.2.5</td>\n",
       "      <td>38792</td>\n",
       "      <td>200.168.87.203</td>\n",
       "      <td>59353</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.998333</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>CGsZqZ3UiQexLzPRVb</td>\n",
       "      <td>192.168.2.5</td>\n",
       "      <td>38792</td>\n",
       "      <td>200.168.87.203</td>\n",
       "      <td>59353</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>C0LkBW2VEa292Nvet8</td>\n",
       "      <td>192.168.2.5</td>\n",
       "      <td>38793</td>\n",
       "      <td>200.168.87.203</td>\n",
       "      <td>59353</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.997182</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>CMDLrn2cVhrqvW8gKa</td>\n",
       "      <td>192.168.2.5</td>\n",
       "      <td>38793</td>\n",
       "      <td>200.168.87.203</td>\n",
       "      <td>59353</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>C2UM8f4knuL5Vnvp3h</td>\n",
       "      <td>192.168.2.5</td>\n",
       "      <td>38794</td>\n",
       "      <td>200.168.87.203</td>\n",
       "      <td>59353</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.996286</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(empty)</td>\n",
       "      <td>Malicious</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts                 uid    id.orig_h  id.orig_p       id.resp_h  \\\n",
       "0  1.526756e+09  C9YvmJ3zxtuqxWxLW5  192.168.2.5      38792  200.168.87.203   \n",
       "1  1.526756e+09  CGsZqZ3UiQexLzPRVb  192.168.2.5      38792  200.168.87.203   \n",
       "2  1.526756e+09  C0LkBW2VEa292Nvet8  192.168.2.5      38793  200.168.87.203   \n",
       "3  1.526756e+09  CMDLrn2cVhrqvW8gKa  192.168.2.5      38793  200.168.87.203   \n",
       "4  1.526756e+09  C2UM8f4knuL5Vnvp3h  192.168.2.5      38794  200.168.87.203   \n",
       "\n",
       "   id.resp_p proto service  duration  orig_bytes  ...  local_resp  \\\n",
       "0      59353   tcp     NaN  2.998333           0  ...        <NA>   \n",
       "1      59353   tcp     NaN       NaN        <NA>  ...        <NA>   \n",
       "2      59353   tcp     NaN  2.997182           0  ...        <NA>   \n",
       "3      59353   tcp     NaN       NaN        <NA>  ...        <NA>   \n",
       "4      59353   tcp     NaN  2.996286           0  ...        <NA>   \n",
       "\n",
       "  missed_bytes  history  orig_pkts  orig_ip_bytes resp_pkts  resp_ip_bytes  \\\n",
       "0            0        S          3            180         0              0   \n",
       "1            0        S          1             60         0              0   \n",
       "2            0        S          3            180         0              0   \n",
       "3            0        S          1             60         0              0   \n",
       "4            0        S          3            180         0              0   \n",
       "\n",
       "   tunnel_parents      label             detailed-label  \n",
       "0        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "1        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "2        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "3        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "4        (empty)   Malicious  PartOfAHorizontalPortScan  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8831bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156103 entries, 0 to 156102\n",
      "Data columns (total 23 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   ts              156103 non-null  float64\n",
      " 1   uid             156103 non-null  object \n",
      " 2   id.orig_h       156103 non-null  object \n",
      " 3   id.orig_p       156103 non-null  Int64  \n",
      " 4   id.resp_h       156103 non-null  object \n",
      " 5   id.resp_p       156103 non-null  Int64  \n",
      " 6   proto           156103 non-null  object \n",
      " 7   service         5908 non-null    object \n",
      " 8   duration        82159 non-null   float64\n",
      " 9   orig_bytes      82159 non-null   Int64  \n",
      " 10  resp_bytes      82159 non-null   Int64  \n",
      " 11  conn_state      156103 non-null  object \n",
      " 12  local_orig      0 non-null       boolean\n",
      " 13  local_resp      0 non-null       boolean\n",
      " 14  missed_bytes    156103 non-null  Int64  \n",
      " 15  history         154896 non-null  object \n",
      " 16  orig_pkts       156103 non-null  Int64  \n",
      " 17  orig_ip_bytes   156103 non-null  Int64  \n",
      " 18  resp_pkts       156103 non-null  Int64  \n",
      " 19  resp_ip_bytes   156103 non-null  Int64  \n",
      " 20  tunnel_parents  156103 non-null  object \n",
      " 21  label           156103 non-null  object \n",
      " 22  detailed-label  156103 non-null  object \n",
      "dtypes: Int64(9), boolean(2), float64(2), object(10)\n",
      "memory usage: 26.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Observe the DataFrame structure and types to check for any inconsistencies\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ec83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 17:24:41,746 - INFO - Dataset cleaned successfully. 0 rows have been removed.\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset using the DataLoader's clean_dataset method that removes duplicates\n",
    "df = Loader.clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1ea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that could provide artificial patterns and prepare the features and labels\n",
    "drop_cols = [\"uid\", \"id.orig_h\", \"id.resp_h\", \"id.orig_p\", \"id.resp_p\",\n",
    "    \"tunnel_parents\", \"service\", \"history\", \"local_orig\", \"local_resp\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=drop_cols + [\"label\",\"detailed-label\"])\n",
    "y = df[\"label\"].map({\"Benign\":0, \"Malicious\":1}).astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca1d9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>proto</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>tcp</td>\n",
       "      <td>2.998333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>tcp</td>\n",
       "      <td>2.997182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>tcp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.526756e+09</td>\n",
       "      <td>tcp</td>\n",
       "      <td>2.996286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts proto  duration  orig_bytes  resp_bytes conn_state  \\\n",
       "0  1.526756e+09   tcp  2.998333           0           0         S0   \n",
       "1  1.526756e+09   tcp       NaN        <NA>        <NA>         S0   \n",
       "2  1.526756e+09   tcp  2.997182           0           0         S0   \n",
       "3  1.526756e+09   tcp       NaN        <NA>        <NA>         S0   \n",
       "4  1.526756e+09   tcp  2.996286           0           0         S0   \n",
       "\n",
       "   missed_bytes  orig_pkts  orig_ip_bytes  resp_pkts  resp_ip_bytes  \n",
       "0             0          3            180          0              0  \n",
       "1             0          1             60          0              0  \n",
       "2             0          3            180          0              0  \n",
       "3             0          1             60          0              0  \n",
       "4             0          3            180          0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few rows of the features DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f3cd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: Int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few rows of the labels Series\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98654094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    0.970942\n",
      "0    0.029058\n",
      "Name: proportion, dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "# Look at the distribution of the labels to check for class imbalance\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b96fd",
   "metadata": {},
   "source": [
    "### Nested Stratified KFold with SearchGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c94db418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the DataProcessor instance\n",
    "Processor = DataProcessor()\n",
    "\n",
    "# Get numerical and categorical columns from the DataFrame manually\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7e767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import kruskal\n",
    "import numpy as np\n",
    "\n",
    "# Define the Kruskal-Wallis score function for feature selection\n",
    "# This function computes the Kruskal-Wallis H statistic for each feature\n",
    "def kruskal_wallis_score(X, y):\n",
    "    scores = []\n",
    "    pvalues = []\n",
    "    for i in range(X.shape[1]):\n",
    "        groups = [X[y == cls, i] for cls in np.unique(y)]\n",
    "        try:\n",
    "            stat, p = kruskal(*groups)\n",
    "        except ValueError:\n",
    "            stat, p = 0, 1\n",
    "        scores.append(stat)\n",
    "        pvalues.append(p)\n",
    "    return np.array(scores), np.array(pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1973c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7942ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the outer and inner cross-validation strategies\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459ec859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Feature Selector: anova...\n",
      "\n",
      " Testing Model: XGBoost...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'training_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 137\u001b[0m\n\u001b[0;32m    122\u001b[0m             os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp_best_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;66;03m#print(f\"[Fold {fold}] Best params: {search.best_params_}\")\u001b[39;00m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;66;03m#print(f\"[Fold {fold}] Features seleccionadas: {selected_features}\")\u001b[39;00m\n\u001b[0;32m    126\u001b[0m             \u001b[38;5;66;03m#print(f\"[Fold {fold}] Confusion matrix:\\n{cm}\")\u001b[39;00m\n\u001b[0;32m    127\u001b[0m             \u001b[38;5;66;03m#print(f\"[Fold {fold}] Classification report:\\n{classification_report(y_test, y_pred, target_names=['Benigno (0)','Malicioso (1)'])}\")\u001b[39;00m\n\u001b[0;32m    129\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    130\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelo\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselector\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROC-AUC\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    133\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUPRC\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauprc\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauprc\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMCC\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcc\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcc\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrier\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrier\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrier\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    136\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFNR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfnr\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfnr\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainTime (s)\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(\u001b[43mouter_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelSize (KB)\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(outer_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatureSelector\u001b[39m\u001b[38;5;124m\"\u001b[39m: selector,\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBestParams_por_fold\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_params_folds,\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBestFeatures_por_fold\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_features_folds,\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusionMatrix_por_fold\u001b[39m\u001b[38;5;124m\"\u001b[39m: confusion_matrixes,\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassificationReport_por_fold\u001b[39m\u001b[38;5;124m\"\u001b[39m: classification_reports\n\u001b[0;32m    144\u001b[0m         })\n\u001b[0;32m    146\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'training_time'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn.metrics import matthews_corrcoef, brier_score_loss, confusion_matrix, classification_report\n",
    "import time, sys\n",
    "import joblib, os\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Define the feature selectors\n",
    "feature_selectors = {\n",
    "    \"anova\": SelectKBest(score_func=f_classif),\n",
    "    \"kruskal\": SelectKBest(score_func=kruskal_wallis_score)\n",
    "}\n",
    "\n",
    "# Define the models and their hyperparameter grids\n",
    "models = {\n",
    "    \"XGBoost\": {\n",
    "        \"estimator\": XGBClassifier(eval_metric=\"logloss\"),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [4, 5],\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__max_depth\": [3, 5, 7],\n",
    "            \"clf__learning_rate\": [0.01, 0.1, 0.2]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"estimator\": RandomForestClassifier(),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [4, 5],\n",
    "            \"clf__n_estimators\": [100],\n",
    "            \"clf__max_depth\": [None, 10, 20],\n",
    "            \"clf__min_samples_split\": [2, 5]\n",
    "        }\n",
    "    },\n",
    "    \"MlpClassifier\": {\n",
    "        \"estimator\": MLPClassifier(max_iter=500, random_state=42),\n",
    "        \"param_grid\": {\n",
    "            \"select__k\": [4, 5],\n",
    "            \"clf__hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "            \"clf__activation\": [\"relu\", \"tanh\"],\n",
    "            \"clf__alpha\": [0.0001, 0.001]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "for selector in feature_selectors.keys():\n",
    "    print(f\"\\nTesting Feature Selector: {selector}...\")\n",
    "    selector_instance = feature_selectors[selector]\n",
    "    for model, configuration in models.items():\n",
    "        estimator = configuration[\"estimator\"]\n",
    "        param_grid = configuration[\"param_grid\"]\n",
    "\n",
    "        print(f\"\\n Testing Model: {model}...\")\n",
    "        outer_scores = {\"f1\": [], \"roc_auc\": [], \"auprc\": [], \"mcc\": [], \"brier\": [], \"fnr\": [], \"training_time\": [], \"size\": []}\n",
    "        best_params_folds = []\n",
    "        best_features_folds = []\n",
    "        confusion_matrixes = []\n",
    "        classification_reports = []\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            pipe = Pipeline([\n",
    "                (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "                (\"select\", clone(selector_instance)),\n",
    "                (\"clf\", estimator)\n",
    "            ])\n",
    "\n",
    "            search = GridSearchCV(\n",
    "                pipe,\n",
    "                param_grid,\n",
    "                scoring=\"f1\",\n",
    "                cv=inner_cv,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            search.fit(X_train, y_train)\n",
    "            train_time = time.perf_counter() - start\n",
    "\n",
    "            best_model = search.best_estimator_\n",
    "            best_params_folds.append(search.best_params_)\n",
    "\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # Metrics\n",
    "            outer_scores[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "            outer_scores[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "            outer_scores[\"auprc\"].append(average_precision_score(y_test, y_proba))\n",
    "            outer_scores[\"mcc\"].append(matthews_corrcoef(y_test, y_pred))\n",
    "            outer_scores[\"brier\"].append(brier_score_loss(y_test, y_proba))\n",
    "            outer_scores[\"trainig_time\"].append(train_time)\n",
    "\n",
    "            # Best Features\n",
    "            select_step = best_model.named_steps[\"select\"]\n",
    "            feature_names = best_model.named_steps[\"pre\"].get_feature_names_out()\n",
    "            selected_mask = select_step.get_support()\n",
    "            selected_features = feature_names[selected_mask]\n",
    "            best_features_folds.append(list(selected_features))\n",
    "\n",
    "            # Confussion matrixes and classification reports\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "            outer_scores[\"fnr\"].append(fnr)\n",
    "            confusion_matrixes.append(cm)\n",
    "\n",
    "            report = classification_report(y_test, y_pred, target_names=[\"Benigno (0)\", \"Malicioso (1)\"], output_dict=True)\n",
    "            classification_reports.append(report)\n",
    "\n",
    "            joblib.dump(best_model, \"tmp_best_model.pkl\")\n",
    "            size_bytes = os.path.getsize(\"tmp_best_model.pkl\")\n",
    "            outer_scores[\"size\"].append(size_bytes / 1024)\n",
    "            os.remove(\"tmp_best_model.pkl\")\n",
    "\n",
    "            #print(f\"[Fold {fold}] Best params: {search.best_params_}\")\n",
    "            #print(f\"[Fold {fold}] Features seleccionadas: {selected_features}\")\n",
    "            #print(f\"[Fold {fold}] Confusion matrix:\\n{cm}\")\n",
    "            #print(f\"[Fold {fold}] Classification report:\\n{classification_report(y_test, y_pred, target_names=['Benigno (0)','Malicioso (1)'])}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Modelo\": f\"{model}_{selector}\",\n",
    "            \"F1\": f\"{np.mean(outer_scores['f1']):.3f} ± {np.std(outer_scores['f1']):.3f}\",\n",
    "            \"ROC-AUC\": f\"{np.mean(outer_scores['roc_auc']):.3f} ± {np.std(outer_scores['roc_auc']):.3f}\",\n",
    "            \"AUPRC\": f\"{np.mean(outer_scores['auprc']):.3f} ± {np.std(outer_scores['auprc']):.3f}\",\n",
    "            \"MCC\": f\"{np.mean(outer_scores['mcc']):.3f} ± {np.std(outer_scores['mcc']):.3f}\",\n",
    "            \"Brier\": f\"{np.mean(outer_scores['brier']):.3f} ± {np.std(outer_scores['brier']):.3f}\",\n",
    "            \"FNR\": f\"{np.mean(outer_scores['fnr']):.3f} ± {np.std(outer_scores['fnr']):.3f}\",\n",
    "            \"TrainTime (s)\": f\"{np.mean(outer_scores['training_time']):.2f} ± {np.std(outer_scores['training_time']):.2f}\",\n",
    "            \"ModelSize (KB)\": f\"{np.mean(outer_scores['size']):.1f} ± {np.std(outer_scores['size']):.1f}\",\n",
    "            \"FeatureSelector\": selector,\n",
    "            \"BestParams_por_fold\": best_params_folds,\n",
    "            \"BestFeatures_por_fold\": best_features_folds,\n",
    "            \"ConfusionMatrix_por_fold\": confusion_matrixes,\n",
    "            \"ClassificationReport_por_fold\": classification_reports\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    selector = row[\"FeatureSelector\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "\n",
    "    print(f\"\\n{modelo} ({selector})\")\n",
    "    print(\"Features más seleccionadas:\")\n",
    "    print(feat_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d764303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFinal Results:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a67011",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    best_params_list = row[\"BestParams_por_fold\"]\n",
    "\n",
    "    params_tuples = [tuple(sorted(d.items())) for d in best_params_list]\n",
    "    params_counts = pd.Series(params_tuples).value_counts()\n",
    "\n",
    "    print(f\"\\n{modelo}\")\n",
    "\n",
    "\n",
    "    best_overall = dict(params_counts.index[0])\n",
    "    print(\"=> Mejor configuración final:\", best_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with simple logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "    (\"clf\", LogisticRegression(max_iter=500))\n",
    "])\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    \"clf__solver\": [\"lbfgs\", \"saga\"]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(pipe, param_grid, scoring=\"f1\", cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Benigno (0)\", \"Malicioso (1)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=[\"conn_state\", \"missed_bytes\", \"proto\"], inplace=True)\n",
    "# Drop conn state, missed bytes and proto\n",
    "cat_cols.remove(\"conn_state\")\n",
    "num_cols.remove(\"missed_bytes\")\n",
    "cat_cols.remove(\"proto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, brier_score_loss, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "best_models = {\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=4)),\n",
    "        (\"clf\", XGBClassifier(eval_metric=\"logloss\", n_estimators=100, max_depth=5, learning_rate=0.1))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=4)),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "    ]),\n",
    "    \"MLPClassifier\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=5)),\n",
    "        (\"clf\", MLPClassifier(hidden_layer_sizes=(50,), activation=\"relu\", alpha=0.0001, max_iter=500, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, pipeline in best_models.items():\n",
    "    print(f\"\\nEvaluando {model_name}...\")\n",
    "\n",
    "    outer_scores = {\"f1\": [], \"roc_auc\": [], \"auprc\": [], \"mcc\": [], \"brier\": [], \"fnr\": [], \"trainig_time\": [], \"size\": []}\n",
    "    confusion_matrixes, classification_reports = [], []\n",
    "    selected_features_folds = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(pipeline)\n",
    "        start = time.perf_counter()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.perf_counter() - start\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        outer_scores[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "        outer_scores[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "        outer_scores[\"auprc\"].append(average_precision_score(y_test, y_proba))\n",
    "        outer_scores[\"mcc\"].append(matthews_corrcoef(y_test, y_pred))\n",
    "        outer_scores[\"brier\"].append(brier_score_loss(y_test, y_proba))\n",
    "        outer_scores[\"trainig_time\"].append(train_time)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        outer_scores[\"fnr\"].append(fnr)\n",
    "        confusion_matrixes.append(cm)\n",
    "\n",
    "        report = classification_report(\n",
    "            y_test, y_pred,\n",
    "            target_names=[\"Benigno (0)\", \"Malicioso (1)\"],\n",
    "            output_dict=True\n",
    "        )\n",
    "        classification_reports.append(report)\n",
    "\n",
    "        select_step = model.named_steps[\"select\"]\n",
    "        feature_names = model.named_steps[\"pre\"].get_feature_names_out()\n",
    "        selected_mask = select_step.get_support()\n",
    "        selected_features = feature_names[selected_mask]\n",
    "        selected_features_folds.append(list(selected_features))\n",
    "\n",
    "        joblib.dump(best_model, \"tmp_best_model.pkl\")\n",
    "        size_bytes = os.path.getsize(\"tmp_best_model.pkl\")\n",
    "        outer_scores[\"size\"].append(size_bytes / 1024)\n",
    "        os.remove(\"tmp_best_model.pkl\")\n",
    "\n",
    "    results.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"F1\": f\"{np.mean(outer_scores['f1']):.3f} ± {np.std(outer_scores['f1']):.3f}\",\n",
    "        \"ROC-AUC\": f\"{np.mean(outer_scores['roc_auc']):.3f} ± {np.std(outer_scores['roc_auc']):.3f}\",\n",
    "        \"AUPRC\": f\"{np.mean(outer_scores['auprc']):.3f} ± {np.std(outer_scores['auprc']):.3f}\",\n",
    "        \"MCC\": f\"{np.mean(outer_scores['mcc']):.3f} ± {np.std(outer_scores['mcc']):.3f}\",\n",
    "        \"Brier\": f\"{np.mean(outer_scores['brier']):.3f} ± {np.std(outer_scores['brier']):.3f}\",\n",
    "        \"FNR\": f\"{np.mean(outer_scores['fnr']):.3f} ± {np.std(outer_scores['fnr']):.3f}\",\n",
    "        \"TrainTime (s)\": f\"{np.mean(outer_scores['training_time']):.2f} ± {np.std(outer_scores['training_time']):.2f}\",\n",
    "        \"ModelSize (KB)\": f\"{np.mean(outer_scores['size']):.\n",
    "        \"ConfusionMatrix_por_fold\": confusion_matrixes,\n",
    "        \"ClassificationReport_por_fold\": classification_reports,\n",
    "        \"BestFeatures_por_fold\": selected_features_folds\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nResultados finales:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\", \"TrainTime (s)\", \"ModelSize (KB)\"]])\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "    print(f\"\\n{modelo} - Features más seleccionadas:\")\n",
    "    print(feat_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aabef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conteos = df[\"detailed-label\"].value_counts()\n",
    "\n",
    "print(conteos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
