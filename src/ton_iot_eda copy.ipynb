{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53901c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reuiqred libraries and data loader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from DataLoader import DataLoader\n",
    "from DataProcessor import DataProcessor\n",
    "\n",
    "Loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44657f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Loader.load_dataset(\"C:/Users/PcVip/Downloads/Network_dataset_2.csv\", file_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3673ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eaba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3135aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Loader.clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17834064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataframe columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take onlu the following columns\n",
    "features = [\n",
    "    \"duration\", \n",
    "    \"src_bytes\", \"dst_bytes\", \n",
    "    \"src_pkts\", \"dst_pkts\", \n",
    "    \"src_ip_bytes\", \"dst_ip_bytes\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"label\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ce016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"duration\", \"src_bytes\", \"dst_bytes\", \"src_pkts\", \"dst_pkts\",\n",
    "            \"src_ip_bytes\", \"dst_ip_bytes\"]:\n",
    "    X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "\n",
    "# divide categorial and numerical columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e20fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numerical columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367918ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data processor\n",
    "processor = DataProcessor(num_cols=num_cols, cat_cols=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Define the outer and inner cross-validation strategies\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, brier_score_loss, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "best_models = {\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=4)),\n",
    "        (\"clf\", XGBClassifier(eval_metric=\"logloss\", n_estimators=100, max_depth=5, learning_rate=0.1))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=4)),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2))\n",
    "    ]),\n",
    "    \"MLPClassifier\": Pipeline([\n",
    "        (\"pre\", DataProcessor(num_cols, cat_cols)),\n",
    "        (\"select\", SelectKBest(score_func=f_classif, k=5)),\n",
    "        (\"clf\", MLPClassifier(hidden_layer_sizes=(50,), activation=\"relu\", alpha=0.0001, max_iter=500, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, pipeline in best_models.items():\n",
    "    print(f\"\\nEvaluando {model_name}...\")\n",
    "\n",
    "    outer_scores = {\"f1\": [], \"roc_auc\": [], \"auprc\": [], \"mcc\": [], \"brier\": [], \"fnr\": []}\n",
    "    confusion_matrixes, classification_reports = [], []\n",
    "    selected_features_folds = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(pipeline)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        outer_scores[\"f1\"].append(f1_score(y_test, y_pred))\n",
    "        outer_scores[\"roc_auc\"].append(roc_auc_score(y_test, y_proba))\n",
    "        outer_scores[\"auprc\"].append(average_precision_score(y_test, y_proba))\n",
    "        outer_scores[\"mcc\"].append(matthews_corrcoef(y_test, y_pred))\n",
    "        outer_scores[\"brier\"].append(brier_score_loss(y_test, y_proba))\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        outer_scores[\"fnr\"].append(fnr)\n",
    "        confusion_matrixes.append(cm)\n",
    "\n",
    "        report = classification_report(\n",
    "            y_test, y_pred,\n",
    "            target_names=[\"Benigno (0)\", \"Malicioso (1)\"],\n",
    "            output_dict=True\n",
    "        )\n",
    "        classification_reports.append(report)\n",
    "\n",
    "        # === Guardar features seleccionadas en este fold ===\n",
    "        select_step = model.named_steps[\"select\"]\n",
    "        feature_names = model.named_steps[\"pre\"].get_feature_names_out()\n",
    "        selected_mask = select_step.get_support()\n",
    "        selected_features = feature_names[selected_mask]\n",
    "        selected_features_folds.append(list(selected_features))\n",
    "\n",
    "    results.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"F1\": f\"{np.mean(outer_scores['f1']):.3f} ± {np.std(outer_scores['f1']):.3f}\",\n",
    "        \"ROC-AUC\": f\"{np.mean(outer_scores['roc_auc']):.3f} ± {np.std(outer_scores['roc_auc']):.3f}\",\n",
    "        \"AUPRC\": f\"{np.mean(outer_scores['auprc']):.3f} ± {np.std(outer_scores['auprc']):.3f}\",\n",
    "        \"MCC\": f\"{np.mean(outer_scores['mcc']):.3f} ± {np.std(outer_scores['mcc']):.3f}\",\n",
    "        \"Brier\": f\"{np.mean(outer_scores['brier']):.3f} ± {np.std(outer_scores['brier']):.3f}\",\n",
    "        \"FNR\": f\"{np.mean(outer_scores['fnr']):.3f} ± {np.std(outer_scores['fnr']):.3f}\",\n",
    "        \"ConfusionMatrix_por_fold\": confusion_matrixes,\n",
    "        \"ClassificationReport_por_fold\": classification_reports,\n",
    "        \"BestFeatures_por_fold\": selected_features_folds\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nResultados finales:\")\n",
    "print(df_results[[\"Modelo\", \"F1\", \"ROC-AUC\", \"AUPRC\", \"MCC\", \"Brier\", \"FNR\"]])\n",
    "\n",
    "# === Contar qué features se repiten más por modelo ===\n",
    "for _, row in df_results.iterrows():\n",
    "    modelo = row[\"Modelo\"]\n",
    "    features_folds = row[\"BestFeatures_por_fold\"]\n",
    "    all_feats = [feat for fold_feats in features_folds for feat in fold_feats]\n",
    "    feat_counts = pd.Series(all_feats).value_counts()\n",
    "    print(f\"\\n{modelo} - Features más seleccionadas:\")\n",
    "    print(feat_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5cff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbbc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\"duration\",\"src_bytes\",\"dst_bytes\",\n",
    "                \"src_pkts\",\"dst_pkts\",\"src_ip_bytes\",\"dst_ip_bytes\"]\n",
    "cat_features = [\"proto\",\"conn_state\",\"service\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_features:\n",
    "    df_prep[col] = pd.to_numeric(df_prep[col], errors=\"coerce\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(df_prep[num_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d401da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "X_cat = ohe.fit_transform(df_prep[cat_features].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cf714",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_num.shape, X_cat.shape)\n",
    "# Ej: (10000, 7) (10000, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b00f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = np.array(X_num)\n",
    "X_cat = np.array(X_cat)\n",
    "\n",
    "print(X_num.shape, X_cat.shape, type(X_num), type(X_cat))\n",
    "\n",
    "X_all = np.hstack([X_num, X_cat])\n",
    "\n",
    "y_all = df_prep[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, window_size=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - window_size):\n",
    "        Xs.append(X[i:(i + window_size)])\n",
    "        ys.append(y[i + window_size])  # etiqueta del último elemento\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_all, y_all, window_size=10)\n",
    "\n",
    "print(\"Shape secuencias:\", X_seq.shape, y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5def0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y_seq, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1355342",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "print(class_weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    GRU(64, input_shape=(X_seq.shape[1], X_seq.shape[2])),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcddf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades\n",
    "y_proba = model.predict(X_test, batch_size=256)\n",
    "\n",
    "# Convertir a 0/1 con umbral 0.5\n",
    "y_pred = (y_proba > 0.75).astype(\"int32\").flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e992ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "# display the confusion matrix with ConfussionMatrxixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Benigno (0)\", \"Malicioso (1)\"])\n",
    "disp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef585d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample, class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score, matthews_corrcoef\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# ============================\n",
    "# Balanceo del dataset\n",
    "# ============================\n",
    "# Aplano para poder hacer oversampling\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "df_train = pd.DataFrame(X_train_flat)\n",
    "df_train[\"label\"] = y_train\n",
    "\n",
    "# Separar clases\n",
    "df_majority = df_train[df_train.label == 1]\n",
    "df_minority = df_train[df_train.label == 0]\n",
    "\n",
    "print(\"Antes del balanceo:\", len(df_majority), \"ataques,\", len(df_minority), \"normales\")\n",
    "\n",
    "# Oversample clase 0\n",
    "df_minority_upsampled = resample(\n",
    "    df_minority,\n",
    "    replace=True,\n",
    "    n_samples=len(df_majority),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Dataset balanceado\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Reconstruir arrays\n",
    "y_train_bal = df_balanced[\"label\"].values\n",
    "X_train_bal = df_balanced.drop(columns=[\"label\"]).values.reshape(-1, X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "print(\"Después del balanceo:\", np.bincount(y_train_bal))\n",
    "\n",
    "# ============================\n",
    "# Pesos de clase (por si queda algo de desbalanceo)\n",
    "# ============================\n",
    "classes = np.unique(y_train_bal)\n",
    "weights = class_weight.compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train_bal)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# ============================\n",
    "# Modelo GRU\n",
    "# ============================\n",
    "model = Sequential([\n",
    "    GRU(64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_bal, y_train_bal,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# Evaluación\n",
    "# ============================\n",
    "y_proba = model.predict(X_test, batch_size=256)\n",
    "y_pred = (y_proba > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e685f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confussion matrix display of y_pred and y_test\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Display the confusion matrix with ConfussionMatrxixDisplay\n",
    "# Display\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Benigno (0)\", \"Malicioso (1)\"])\n",
    "disp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b0a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install imbalanced-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score, matthews_corrcoef\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# ============================\n",
    "# SMOTE para balancear dataset\n",
    "# ============================\n",
    "print(\"Original balance:\", np.bincount(y_train))\n",
    "\n",
    "# Flatten para SMOTE\n",
    "n_samples, timesteps, n_features = X_train.shape\n",
    "X_train_flat = X_train.reshape((n_samples, timesteps * n_features))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_flat, y_train)\n",
    "\n",
    "# Reconstruir 3D para GRU\n",
    "X_train_bal = X_train_bal.reshape((-1, timesteps, n_features))\n",
    "print(\"Balance después de SMOTE:\", np.bincount(y_train_bal))\n",
    "\n",
    "# ============================\n",
    "# Focal Loss\n",
    "# ============================\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        pt = tf.exp(-bce)\n",
    "        return alpha * (1 - pt) ** gamma * bce\n",
    "    return loss\n",
    "\n",
    "# ============================\n",
    "# Modelo GRU\n",
    "# ============================\n",
    "model = Sequential([\n",
    "    GRU(64, input_shape=(timesteps, n_features)),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss=focal_loss(gamma=2., alpha=0.75),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_bal, y_train_bal,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# Evaluación\n",
    "# ============================\n",
    "y_proba = model.predict(X_test, batch_size=256)\n",
    "y_pred = (y_proba > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "# ============================\n",
    "# Visualizar matriz de confusión\n",
    "# ============================\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal (0)\",\"Ataque (1)\"], yticklabels=[\"Normal (0)\",\"Ataque (1)\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - GRU + SMOTE + Focal Loss\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
